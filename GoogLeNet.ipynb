{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-train on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "# net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 250], gamma=0.1)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(trainloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(testloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('/tmp/work/checkpoint'):\n",
    "            os.mkdir('/tmp/work/checkpoint')\n",
    "        torch.save(state, '/tmp/work/checkpoint/googLeNet.cifar10.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, 350):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing accuracy: >90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on CINIC-10\n",
    "\n",
    "- train: train set\n",
    "- valid: valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Train CINIC10 with PyTorch.'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/train/', transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/valid/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "# net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load checkpoint.\n",
    "# print('==> Resuming from checkpoint..')\n",
    "# checkpoint = torch.load('/tmp/work/checkpoint/ckpt.cinic10.0.t7')#'/tmp/work/checkpoint/ckpt.cifar10.t7')\n",
    "# net.load_state_dict(checkpoint['net'])\n",
    "#start_epoch = checkpoint['epoch']\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 250, 450], gamma=0.1)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(trainloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(testloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('/tmp/work/checkpoint'):\n",
    "            os.mkdir('/tmp/work/checkpoint')\n",
    "        torch.save(state, '/tmp/work/checkpoint/googLeNet.cinic10.0.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, 601):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full CINIC-10\n",
    "\n",
    "- train: train set + valid set\n",
    "- valid: test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Train CINIC10 with PyTorch.'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/train/', transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "validset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/valid/', transform=transform_train)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/test/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "# net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load('/tmp/work/checkpoint/ckpt.cinic10.0.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 250, 450], gamma=0.2)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(trainloader)+len(validloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "        for batch_idx, (inputs, targets) in enumerate(validloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(testloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('/tmp/work/checkpoint'):\n",
    "            os.mkdir('/tmp/work/checkpoint')\n",
    "        torch.save(state, '/tmp/work/checkpoint/ckpt.cinic10.1.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "for epoch in range(start_epoch, 601):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full CINIC-10 with data augmentation\n",
    "\n",
    "- train: train set + valid set\n",
    "- valid: test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Train CINIC10 with PyTorch.'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.SomeOf((0, 3), [\n",
    "                iaa.Affine(rotate=iap.Uniform(0.0, 360.0)),\n",
    "                iaa.CropAndPad(percent=(-0.2, 0)),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "                iaa.AdditiveGaussianNoise(scale=0.1*255),\n",
    "                iaa.Sharpen(alpha=0.5),\n",
    "                iaa.PiecewiseAffine(scale=iap.Uniform(0.02, 0.08), \n",
    "                                    nb_rows=iap.Uniform(4,8),\n",
    "                                    nb_cols=iap.Uniform(4,8))\n",
    "            ]),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    #ImgAugTransform(),\n",
    "    #lambda x: PIL.Image.fromarray(x),\n",
    "    transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/train/', transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "validset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/valid/', transform=transform_train)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=128, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/test/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "# net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load('/tmp/work/checkpoint/ckpt.cinic10.1.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 250, 450], gamma=0.5)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(trainloader)+len(validloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "        for batch_idx, (inputs, targets) in enumerate(validloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(testloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('/tmp/work/checkpoint'):\n",
    "            os.mkdir('/tmp/work/checkpoint')\n",
    "        torch.save(state, '/tmp/work/checkpoint/ckpt.cinic10.2.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, 701):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_name = 'cinic10.0'\n",
    "_path = '../mobileNetV2.{}.pth'.format(_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'net': net.module.state_dict(),\n",
    "    'acc': checkpoint['acc'],\n",
    "    'epoch': checkpoint['epoch'],\n",
    "}\n",
    "\n",
    "torch.save(state, _path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "# net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "\n",
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load(_path)\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "# Export model\n",
    "print('==> Exporting model..')\n",
    "dummy_input = Variable(torch.randn(1, 3, 32, 32), requires_grad=False)\n",
    "torch.onnx.export(net, dummy_input, \"../mobileNetV2.{}.onnx\".format(_name), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorRT deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "\n",
    "def build_engine(onnx_model='./resnet18_food11.onnx', max_batch_size=256):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        # Configure the builder here.\n",
    "        builder.max_batch_size = max_batch_size\n",
    "        builder.max_workspace_size = 1 <<  20\n",
    "        # Parse the model to create a network.\n",
    "        with open(onnx_model, 'rb') as model:\n",
    "            parser.parse(model.read())\n",
    "        # Build and return the engine. Note that the builder, network and parser are destroyed when this function returns.\n",
    "        return builder.build_cuda_engine(network)\n",
    "    \n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\n",
    "def allocate_buffers(engine):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    bindings = []\n",
    "    stream = cuda.Stream()\n",
    "    for binding in engine:\n",
    "        size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "        # Allocate host and device buffers\n",
    "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "        # Append the device buffer to device bindings.\n",
    "        bindings.append(int(device_mem))\n",
    "        # Append to the appropriate list.\n",
    "        if engine.binding_is_input(binding):\n",
    "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "        else:\n",
    "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    return inputs, outputs, bindings, stream\n",
    "\n",
    "def do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.init()\n",
    "\n",
    "max_batch_size = 1024\n",
    "onnx_model = '../mobileNetV2.cifar10.onnx'\n",
    "engine = build_engine(onnx_model, max_batch_size=max_batch_size)\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# input_image_paths = glob.glob('./data/*.npy')\n",
    "# images = []\n",
    "# labels = []\n",
    "# for im_path in input_image_paths:\n",
    "#     image = np.load(im_path)\n",
    "#     images.append(image)\n",
    "#     labels.append(os.path.basename(im_path).split(sep='_')[0])\n",
    "# images = np.asarray(images)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "testset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/test/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "print('batch size: ' + str(batch_size))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "inputs, outputs, bindings, stream = allocate_buffers(engine)\n",
    "#for idx in range(0, len(images), batch_size):\n",
    "for idx, (images, labels) in enumerate(testloader):\n",
    "    images = np.asarray(images)\n",
    "    inputs[0].host = images[idx: idx+batch_size]\n",
    "    pred = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, \n",
    "                        stream=stream, batch_size=batch_size)\n",
    "    pred = np.asarray(pred).reshape(-1,10)\n",
    "    pred = np.argmax(pred)\n",
    "    correct += np.sum(pred == labels)\n",
    "    total += len(labels)\n",
    "#     for i in range(len(images)):\n",
    "#         predicted_label = str(np.argmax(pred[i]))\n",
    "#         if(predicted_label == labels[idx+i]):\n",
    "#             correct += 1\n",
    "accuracy = correct / total\n",
    "print('acc: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import sys\n",
    "data_dir = \"/tmp/work/data/CINIC-10/test/\"\n",
    "assert data_dir is not None, \"No data directory\"\n",
    "\n",
    "from models import *\n",
    "checkpoint = torch.load('../mobileNetV2.cinic10.0.pth')\n",
    "model = MobileNetV2()\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def inference(model, testloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    model.to(device)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.cuda()).sum().item()\n",
    "    acc = 100.*correct/total\n",
    "    print(acc)\n",
    "    return acc\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "#testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testset = torchvision.datasets.ImageFolder(root=data_dir, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "inference(model, testloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlsr",
   "language": "python",
   "name": "dlsr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
