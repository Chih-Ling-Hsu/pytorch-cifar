{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-train on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 39.890%: 100%|█████████▉| 391/392 [00:34<00:00, 11.46it/s]\n",
      "Acc: 47.020%:  99%|█████████▉| 100/101 [00:02<00:00, 44.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 58.352%: 100%|█████████▉| 391/392 [00:32<00:00, 12.83it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 66.324%: 100%|█████████▉| 391/392 [00:32<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 71.010%: 100%|█████████▉| 391/392 [00:32<00:00, 12.84it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 74.258%: 100%|█████████▉| 391/392 [00:32<00:00, 12.77it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 75.746%: 100%|█████████▉| 391/392 [00:32<00:00, 12.70it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.062%: 100%|█████████▉| 391/392 [00:32<00:00, 12.79it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 78.934%: 100%|█████████▉| 391/392 [00:32<00:00, 12.81it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.096%: 100%|█████████▉| 391/392 [00:32<00:00, 12.74it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.660%: 100%|█████████▉| 391/392 [00:32<00:00, 12.77it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.370%: 100%|█████████▉| 391/392 [00:32<00:00, 12.83it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.545%:  50%|█████     | 197/392 [00:16<00:15, 12.27it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Acc: 79.958%: 100%|█████████▉| 391/392 [00:32<00:00, 12.83it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.096%: 100%|█████████▉| 391/392 [00:32<00:00, 12.79it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.530%: 100%|█████████▉| 391/392 [00:32<00:00, 12.80it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.254%: 100%|█████████▉| 391/392 [00:32<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.330%: 100%|█████████▉| 391/392 [00:32<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.108%:  13%|█▎        | 51/392 [00:04<00:27, 12.27it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Acc: 80.054%: 100%|█████████▉| 391/392 [00:32<00:00, 12.85it/s]\n",
      "Acc: 72.400%:  99%|█████████▉| 100/101 [00:02<00:00, 42.70it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.606%: 100%|█████████▉| 391/392 [00:31<00:00, 12.82it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.560%: 100%|█████████▉| 391/392 [00:32<00:00, 12.81it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.346%: 100%|█████████▉| 391/392 [00:32<00:00, 12.82it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.304%: 100%|█████████▉| 391/392 [00:32<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.450%: 100%|█████████▉| 391/392 [00:32<00:00, 12.82it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.040%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.324%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "Acc: 76.830%:  99%|█████████▉| 100/101 [00:02<00:00, 43.06it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.500%: 100%|█████████▉| 391/392 [00:31<00:00, 12.83it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.082%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.948%: 100%|█████████▉| 391/392 [00:32<00:00, 12.83it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.418%: 100%|█████████▉| 391/392 [00:32<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.277%:  50%|████▉     | 195/392 [00:16<00:16, 12.25it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Acc: 79.874%: 100%|█████████▉| 391/392 [00:32<00:00, 12.86it/s]\n",
      "Acc: 74.090%:  99%|█████████▉| 100/101 [00:02<00:00, 43.72it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.428%: 100%|█████████▉| 391/392 [00:32<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.268%: 100%|█████████▉| 391/392 [00:32<00:00, 12.81it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.400%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.294%: 100%|█████████▉| 391/392 [00:32<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.140%:  86%|████████▋ | 339/392 [00:27<00:04, 12.23it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Acc: 80.256%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.040%: 100%|█████████▉| 391/392 [00:32<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.260%: 100%|█████████▉| 391/392 [00:32<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.234%: 100%|█████████▉| 391/392 [00:32<00:00, 12.81it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.076%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.316%: 100%|█████████▉| 391/392 [00:32<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.138%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.446%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.110%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.256%: 100%|█████████▉| 391/392 [00:31<00:00, 12.85it/s]\n",
      "Acc: 77.250%:  99%|█████████▉| 100/101 [00:02<00:00, 42.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.942%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.802%: 100%|█████████▉| 391/392 [00:31<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.086%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.086%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.928%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.030%: 100%|█████████▉| 391/392 [00:31<00:00, 13.00it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.958%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.670%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.656%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.846%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "Acc: 75.550%:  99%|█████████▉| 100/101 [00:02<00:00, 42.79it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.770%: 100%|█████████▉| 391/392 [00:31<00:00, 13.08it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.992%: 100%|█████████▉| 391/392 [00:32<00:00, 12.84it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.788%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.706%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.040%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.148%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.882%: 100%|█████████▉| 391/392 [00:31<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.716%: 100%|█████████▉| 391/392 [00:31<00:00, 12.74it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.016%: 100%|█████████▉| 391/392 [00:32<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.128%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "Acc: 71.570%:  99%|█████████▉| 100/101 [00:02<00:00, 40.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.008%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.896%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.414%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 80.006%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.244%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.278%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.252%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.298%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.884%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.632%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "Acc: 78.930%:  99%|█████████▉| 100/101 [00:02<00:00, 42.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.456%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.366%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.372%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.488%: 100%|█████████▉| 391/392 [00:31<00:00, 13.00it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.780%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.462%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.412%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.698%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.442%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.670%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "Acc: 74.670%:  99%|█████████▉| 100/101 [00:02<00:00, 42.65it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.682%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.626%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.478%: 100%|█████████▉| 391/392 [00:31<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.362%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.608%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.436%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.244%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.548%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.138%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.032%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "Acc: 75.100%:  99%|█████████▉| 100/101 [00:02<00:00, 42.70it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.344%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.244%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.264%: 100%|█████████▉| 391/392 [00:31<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.166%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.242%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.524%: 100%|█████████▉| 391/392 [00:31<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.190%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.120%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 78.830%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.270%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "Acc: 75.880%:  99%|█████████▉| 100/101 [00:02<00:00, 42.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 78.784%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.314%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.018%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 78.968%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.078%: 100%|█████████▉| 391/392 [00:31<00:00, 12.82it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 78.976%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.192%: 100%|█████████▉| 391/392 [00:32<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 78.798%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.046%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 78.834%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "Acc: 74.530%:  99%|█████████▉| 100/101 [00:02<00:00, 42.78it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 78.874%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.126%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.244%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.044%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.018%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 79.012%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 84.986%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "Acc: 86.380%:  99%|█████████▉| 100/101 [00:02<00:00, 43.05it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 87.068%:  70%|███████   | 276/392 [00:22<00:09, 12.31it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Acc: 89.210%: 100%|█████████▉| 391/392 [00:32<00:00, 12.81it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.314%: 100%|█████████▉| 391/392 [00:32<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.316%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.540%: 100%|█████████▉| 391/392 [00:31<00:00, 12.98it/s]\n",
      "Acc: 87.940%:  99%|█████████▉| 100/101 [00:02<00:00, 42.73it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.706%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.696%:   3%|▎         | 10/392 [00:01<00:45,  8.34it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Acc: 89.684%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.908%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.672%: 100%|█████████▉| 391/392 [00:32<00:00, 12.83it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.770%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "Acc: 88.160%:  99%|█████████▉| 100/101 [00:02<00:00, 40.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.924%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.874%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.898%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.860%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.986%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.066%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.724%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.778%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.818%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.872%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "Acc: 87.770%:  99%|█████████▉| 100/101 [00:02<00:00, 42.82it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.858%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.430%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.944%: 100%|█████████▉| 391/392 [00:31<00:00, 13.06it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.984%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.032%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.808%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.758%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.912%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.836%: 100%|█████████▉| 391/392 [00:31<00:00, 12.81it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.082%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "Acc: 87.850%:  99%|█████████▉| 100/101 [00:02<00:00, 42.02it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.826%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.686%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.872%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.838%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.872%: 100%|█████████▉| 391/392 [00:32<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.744%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.644%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.902%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.718%: 100%|█████████▉| 391/392 [00:32<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.110%: 100%|█████████▉| 391/392 [00:32<00:00, 12.85it/s]\n",
      "Acc: 87.600%:  99%|█████████▉| 100/101 [00:02<00:00, 42.82it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.220%: 100%|█████████▉| 391/392 [00:31<00:00, 12.83it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.080%: 100%|█████████▉| 391/392 [00:31<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.926%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.096%: 100%|█████████▉| 391/392 [00:31<00:00, 12.82it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.906%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.742%: 100%|█████████▉| 391/392 [00:31<00:00, 12.98it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.102%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.994%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.002%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.236%: 100%|█████████▉| 391/392 [00:32<00:00, 12.96it/s]\n",
      "Acc: 87.630%:  99%|█████████▉| 100/101 [00:02<00:00, 42.54it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.182%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.008%: 100%|█████████▉| 391/392 [00:31<00:00, 12.98it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.072%: 100%|█████████▉| 391/392 [00:31<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.040%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.950%: 100%|█████████▉| 391/392 [00:31<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.092%: 100%|█████████▉| 391/392 [00:31<00:00, 12.99it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.062%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.052%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.082%: 100%|█████████▉| 391/392 [00:31<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.154%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "Acc: 87.800%:  99%|█████████▉| 100/101 [00:02<00:00, 42.67it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.146%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.894%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.984%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.222%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.266%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.188%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.230%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.242%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.358%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 89.986%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "Acc: 88.260%:  99%|█████████▉| 100/101 [00:02<00:00, 41.59it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.346%: 100%|█████████▉| 391/392 [00:32<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.414%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.272%: 100%|█████████▉| 391/392 [00:32<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.312%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.252%: 100%|█████████▉| 391/392 [00:32<00:00, 12.83it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.326%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.622%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.480%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.170%: 100%|█████████▉| 391/392 [00:32<00:00, 12.84it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.418%: 100%|█████████▉| 391/392 [00:32<00:00, 12.82it/s]\n",
      "Acc: 85.800%:  99%|█████████▉| 100/101 [00:02<00:00, 42.16it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.570%: 100%|█████████▉| 391/392 [00:32<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.560%: 100%|█████████▉| 391/392 [00:32<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.562%: 100%|█████████▉| 391/392 [00:32<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.452%: 100%|█████████▉| 391/392 [00:32<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.528%: 100%|█████████▉| 391/392 [00:32<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.344%: 100%|█████████▉| 391/392 [00:31<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.466%: 100%|█████████▉| 391/392 [00:32<00:00, 12.84it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.628%: 100%|█████████▉| 391/392 [00:32<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 90.558%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 92.814%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "Acc: 90.650%:  99%|█████████▉| 100/101 [00:02<00:00, 42.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 93.856%: 100%|█████████▉| 391/392 [00:32<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 94.168%: 100%|█████████▉| 391/392 [00:32<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 94.476%: 100%|█████████▉| 391/392 [00:32<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 94.618%: 100%|█████████▉| 391/392 [00:32<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 94.622%: 100%|█████████▉| 391/392 [00:32<00:00, 12.84it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 94.648%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 94.774%: 100%|█████████▉| 391/392 [00:32<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 94.928%: 100%|█████████▉| 391/392 [00:32<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 94.930%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.050%: 100%|█████████▉| 391/392 [00:32<00:00, 12.85it/s]\n",
      "Acc: 91.180%:  99%|█████████▉| 100/101 [00:02<00:00, 41.54it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.014%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.208%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.092%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.214%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.266%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.320%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.436%: 100%|█████████▉| 391/392 [00:31<00:00, 12.90it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.442%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.580%: 100%|█████████▉| 391/392 [00:32<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.526%: 100%|█████████▉| 391/392 [00:31<00:00, 13.13it/s]\n",
      "Acc: 91.090%:  99%|█████████▉| 100/101 [00:02<00:00, 40.22it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.484%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.634%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.584%: 100%|█████████▉| 391/392 [00:31<00:00, 13.14it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.442%: 100%|█████████▉| 391/392 [00:32<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.538%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.656%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.770%: 100%|█████████▉| 391/392 [00:32<00:00, 12.78it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.826%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.636%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.784%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "Acc: 90.940%:  99%|█████████▉| 100/101 [00:02<00:00, 41.47it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.818%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.766%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.832%: 100%|█████████▉| 391/392 [00:31<00:00, 13.00it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.844%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.854%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.988%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.850%: 100%|█████████▉| 391/392 [00:31<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.780%: 100%|█████████▉| 391/392 [00:31<00:00, 12.99it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.890%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.986%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "Acc: 91.120%:  99%|█████████▉| 100/101 [00:02<00:00, 41.59it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.896%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.950%: 100%|█████████▉| 391/392 [00:31<00:00, 13.03it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 95.988%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.032%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.042%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.086%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.034%: 100%|█████████▉| 391/392 [00:31<00:00, 12.98it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.032%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.016%: 100%|█████████▉| 391/392 [00:31<00:00, 12.88it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.080%: 100%|█████████▉| 391/392 [00:31<00:00, 13.12it/s]\n",
      "Acc: 90.960%:  99%|█████████▉| 100/101 [00:02<00:00, 42.55it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.174%: 100%|█████████▉| 391/392 [00:31<00:00, 12.98it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.088%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.098%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.208%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.042%: 100%|█████████▉| 391/392 [00:31<00:00, 13.00it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.114%: 100%|█████████▉| 391/392 [00:31<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.022%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.210%: 100%|█████████▉| 391/392 [00:32<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.160%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.228%: 100%|█████████▉| 391/392 [00:31<00:00, 12.97it/s]\n",
      "Acc: 91.260%:  99%|█████████▉| 100/101 [00:02<00:00, 40.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.132%: 100%|█████████▉| 391/392 [00:32<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.336%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.334%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.248%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.222%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.280%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.194%: 100%|█████████▉| 391/392 [00:31<00:00, 13.00it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.316%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.408%: 100%|█████████▉| 391/392 [00:31<00:00, 12.97it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.404%: 100%|█████████▉| 391/392 [00:31<00:00, 12.98it/s]\n",
      "Acc: 91.000%:  99%|█████████▉| 100/101 [00:02<00:00, 39.60it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.302%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.290%: 100%|█████████▉| 391/392 [00:31<00:00, 13.05it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.376%: 100%|█████████▉| 391/392 [00:32<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.452%: 100%|█████████▉| 391/392 [00:31<00:00, 12.98it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.290%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.438%: 100%|█████████▉| 391/392 [00:31<00:00, 12.93it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.374%: 100%|█████████▉| 391/392 [00:31<00:00, 13.03it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.454%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.428%: 100%|█████████▉| 391/392 [00:31<00:00, 12.86it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.474%: 100%|█████████▉| 391/392 [00:31<00:00, 13.03it/s]\n",
      "Acc: 91.100%:  99%|█████████▉| 100/101 [00:02<00:00, 41.77it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.376%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.388%: 100%|█████████▉| 391/392 [00:31<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.568%: 100%|█████████▉| 391/392 [00:32<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.460%: 100%|█████████▉| 391/392 [00:32<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.388%: 100%|█████████▉| 391/392 [00:32<00:00, 12.84it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.370%: 100%|█████████▉| 391/392 [00:31<00:00, 12.94it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.404%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.328%: 100%|█████████▉| 391/392 [00:32<00:00, 12.82it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.404%: 100%|█████████▉| 391/392 [00:32<00:00, 12.87it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.474%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "Acc: 90.870%:  99%|█████████▉| 100/101 [00:02<00:00, 42.12it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.606%: 100%|█████████▉| 391/392 [00:31<00:00, 12.92it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.516%: 100%|█████████▉| 391/392 [00:31<00:00, 12.89it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.514%: 100%|█████████▉| 391/392 [00:31<00:00, 12.85it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.564%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.472%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.606%: 100%|█████████▉| 391/392 [00:31<00:00, 12.96it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.574%: 100%|█████████▉| 391/392 [00:31<00:00, 12.91it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.480%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n",
      "  0%|          | 0/392 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 96.544%: 100%|█████████▉| 391/392 [00:31<00:00, 12.95it/s]\n"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "# net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 250], gamma=0.1)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(trainloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(testloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('/tmp/work/checkpoint'):\n",
    "            os.mkdir('/tmp/work/checkpoint')\n",
    "        torch.save(state, '/tmp/work/checkpoint/ckpt.cifar10.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, 350):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing accuracy: >90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on CINIC-10\n",
    "\n",
    "- train: train set\n",
    "- valid: valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train CINIC10 with PyTorch.'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/train/', transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/valid/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "# net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load('/tmp/work/checkpoint/ckpt.cifar10.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "#start_epoch = checkpoint['epoch']\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 250], gamma=0.1)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(trainloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(testloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('/tmp/work/checkpoint'):\n",
    "            os.mkdir('/tmp/work/checkpoint')\n",
    "        torch.save(state, '/tmp/work/checkpoint/ckpt.cinic10.0.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, 350):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy 77%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full CINIC-10\n",
    "\n",
    "- train: train set + valid set\n",
    "- valid: test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train CINIC10 with PyTorch.'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "from utils import progress_bar\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/train/', transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "validset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/valid/', transform=transform_train)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/test/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "# net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load('/tmp/work/checkpoint/ckpt.cinic10.0.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 250], gamma=0.1)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(trainloader)+len(validloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "        for batch_idx, (inputs, targets) in enumerate(validloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(testloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('/tmp/work/checkpoint'):\n",
    "            os.mkdir('/tmp/work/checkpoint')\n",
    "        torch.save(state, '/tmp/work/checkpoint/ckpt.cinic10.1.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "for epoch in range(start_epoch, 350):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on full CINIC-10 with data augmentation\n",
    "\n",
    "- train: train set + valid set\n",
    "- valid: test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train CINIC10 with PyTorch.'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "from utils import progress_bar\n",
    "\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from imgaug import parameters as iap\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "            iaa.SomeOf((0, 2), [\n",
    "                iaa.Affine(rotate=iap.Uniform(0.0, 360.0)),\n",
    "                iaa.CropAndPad(percent=(-0.2, 0)),\n",
    "                iaa.Fliplr(0.5),\n",
    "                iaa.Flipud(0.5),\n",
    "                iaa.AdditiveGaussianNoise(scale=0.1*255),\n",
    "                iaa.Sharpen(alpha=0.5),\n",
    "                iaa.PiecewiseAffine(scale=iap.Uniform(0.02, 0.08), \n",
    "                                    nb_rows=iap.Uniform(4,8),\n",
    "                                    nb_cols=iap.Uniform(4,8))\n",
    "            ]),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "    ImgAugTransform(),\n",
    "    lambda x: PIL.Image.fromarray(x),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/train/', transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "validset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/valid/', transform=transform_train)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/test/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "# net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load('/tmp/work/checkpoint/ckpt.cinic10.1.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 250], gamma=0.1)\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(trainloader)+len(validloader)) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "        for batch_idx, (inputs, targets) in enumerate(validloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "            pbar.update(1)\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(total=len(testloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "                pbar.set_description('Acc: %.3f%%' % (100.*correct/total))\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('/tmp/work/checkpoint'):\n",
    "            os.mkdir('/tmp/work/checkpoint')\n",
    "        torch.save(state, '/tmp/work/checkpoint/ckpt.cinic10.2.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, 350):\n",
    "    scheduler.step()\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "==> Resuming from checkpoint..\n",
      "==> Exporting model..\n",
      "graph(%0 : Float(1, 3, 32, 32)\n",
      "      %1 : Float(32, 3, 3, 3)\n",
      "      %2 : Float(32)\n",
      "      %3 : Float(32)\n",
      "      %4 : Float(32)\n",
      "      %5 : Float(32)\n",
      "      %6 : Float(32, 32, 1, 1)\n",
      "      %7 : Float(32)\n",
      "      %8 : Float(32)\n",
      "      %9 : Float(32)\n",
      "      %10 : Float(32)\n",
      "      %11 : Float(32, 1, 3, 3)\n",
      "      %12 : Float(32)\n",
      "      %13 : Float(32)\n",
      "      %14 : Float(32)\n",
      "      %15 : Float(32)\n",
      "      %16 : Float(16, 32, 1, 1)\n",
      "      %17 : Float(16)\n",
      "      %18 : Float(16)\n",
      "      %19 : Float(16)\n",
      "      %20 : Float(16)\n",
      "      %21 : Float(16, 32, 1, 1)\n",
      "      %22 : Float(16)\n",
      "      %23 : Float(16)\n",
      "      %24 : Float(16)\n",
      "      %25 : Float(16)\n",
      "      %26 : Float(96, 16, 1, 1)\n",
      "      %27 : Float(96)\n",
      "      %28 : Float(96)\n",
      "      %29 : Float(96)\n",
      "      %30 : Float(96)\n",
      "      %31 : Float(96, 1, 3, 3)\n",
      "      %32 : Float(96)\n",
      "      %33 : Float(96)\n",
      "      %34 : Float(96)\n",
      "      %35 : Float(96)\n",
      "      %36 : Float(24, 96, 1, 1)\n",
      "      %37 : Float(24)\n",
      "      %38 : Float(24)\n",
      "      %39 : Float(24)\n",
      "      %40 : Float(24)\n",
      "      %41 : Float(24, 16, 1, 1)\n",
      "      %42 : Float(24)\n",
      "      %43 : Float(24)\n",
      "      %44 : Float(24)\n",
      "      %45 : Float(24)\n",
      "      %46 : Float(144, 24, 1, 1)\n",
      "      %47 : Float(144)\n",
      "      %48 : Float(144)\n",
      "      %49 : Float(144)\n",
      "      %50 : Float(144)\n",
      "      %51 : Float(144, 1, 3, 3)\n",
      "      %52 : Float(144)\n",
      "      %53 : Float(144)\n",
      "      %54 : Float(144)\n",
      "      %55 : Float(144)\n",
      "      %56 : Float(24, 144, 1, 1)\n",
      "      %57 : Float(24)\n",
      "      %58 : Float(24)\n",
      "      %59 : Float(24)\n",
      "      %60 : Float(24)\n",
      "      %61 : Float(144, 24, 1, 1)\n",
      "      %62 : Float(144)\n",
      "      %63 : Float(144)\n",
      "      %64 : Float(144)\n",
      "      %65 : Float(144)\n",
      "      %66 : Float(144, 1, 3, 3)\n",
      "      %67 : Float(144)\n",
      "      %68 : Float(144)\n",
      "      %69 : Float(144)\n",
      "      %70 : Float(144)\n",
      "      %71 : Float(32, 144, 1, 1)\n",
      "      %72 : Float(32)\n",
      "      %73 : Float(32)\n",
      "      %74 : Float(32)\n",
      "      %75 : Float(32)\n",
      "      %76 : Float(192, 32, 1, 1)\n",
      "      %77 : Float(192)\n",
      "      %78 : Float(192)\n",
      "      %79 : Float(192)\n",
      "      %80 : Float(192)\n",
      "      %81 : Float(192, 1, 3, 3)\n",
      "      %82 : Float(192)\n",
      "      %83 : Float(192)\n",
      "      %84 : Float(192)\n",
      "      %85 : Float(192)\n",
      "      %86 : Float(32, 192, 1, 1)\n",
      "      %87 : Float(32)\n",
      "      %88 : Float(32)\n",
      "      %89 : Float(32)\n",
      "      %90 : Float(32)\n",
      "      %91 : Float(192, 32, 1, 1)\n",
      "      %92 : Float(192)\n",
      "      %93 : Float(192)\n",
      "      %94 : Float(192)\n",
      "      %95 : Float(192)\n",
      "      %96 : Float(192, 1, 3, 3)\n",
      "      %97 : Float(192)\n",
      "      %98 : Float(192)\n",
      "      %99 : Float(192)\n",
      "      %100 : Float(192)\n",
      "      %101 : Float(32, 192, 1, 1)\n",
      "      %102 : Float(32)\n",
      "      %103 : Float(32)\n",
      "      %104 : Float(32)\n",
      "      %105 : Float(32)\n",
      "      %106 : Float(192, 32, 1, 1)\n",
      "      %107 : Float(192)\n",
      "      %108 : Float(192)\n",
      "      %109 : Float(192)\n",
      "      %110 : Float(192)\n",
      "      %111 : Float(192, 1, 3, 3)\n",
      "      %112 : Float(192)\n",
      "      %113 : Float(192)\n",
      "      %114 : Float(192)\n",
      "      %115 : Float(192)\n",
      "      %116 : Float(64, 192, 1, 1)\n",
      "      %117 : Float(64)\n",
      "      %118 : Float(64)\n",
      "      %119 : Float(64)\n",
      "      %120 : Float(64)\n",
      "      %121 : Float(384, 64, 1, 1)\n",
      "      %122 : Float(384)\n",
      "      %123 : Float(384)\n",
      "      %124 : Float(384)\n",
      "      %125 : Float(384)\n",
      "      %126 : Float(384, 1, 3, 3)\n",
      "      %127 : Float(384)\n",
      "      %128 : Float(384)\n",
      "      %129 : Float(384)\n",
      "      %130 : Float(384)\n",
      "      %131 : Float(64, 384, 1, 1)\n",
      "      %132 : Float(64)\n",
      "      %133 : Float(64)\n",
      "      %134 : Float(64)\n",
      "      %135 : Float(64)\n",
      "      %136 : Float(384, 64, 1, 1)\n",
      "      %137 : Float(384)\n",
      "      %138 : Float(384)\n",
      "      %139 : Float(384)\n",
      "      %140 : Float(384)\n",
      "      %141 : Float(384, 1, 3, 3)\n",
      "      %142 : Float(384)\n",
      "      %143 : Float(384)\n",
      "      %144 : Float(384)\n",
      "      %145 : Float(384)\n",
      "      %146 : Float(64, 384, 1, 1)\n",
      "      %147 : Float(64)\n",
      "      %148 : Float(64)\n",
      "      %149 : Float(64)\n",
      "      %150 : Float(64)\n",
      "      %151 : Float(384, 64, 1, 1)\n",
      "      %152 : Float(384)\n",
      "      %153 : Float(384)\n",
      "      %154 : Float(384)\n",
      "      %155 : Float(384)\n",
      "      %156 : Float(384, 1, 3, 3)\n",
      "      %157 : Float(384)\n",
      "      %158 : Float(384)\n",
      "      %159 : Float(384)\n",
      "      %160 : Float(384)\n",
      "      %161 : Float(64, 384, 1, 1)\n",
      "      %162 : Float(64)\n",
      "      %163 : Float(64)\n",
      "      %164 : Float(64)\n",
      "      %165 : Float(64)\n",
      "      %166 : Float(384, 64, 1, 1)\n",
      "      %167 : Float(384)\n",
      "      %168 : Float(384)\n",
      "      %169 : Float(384)\n",
      "      %170 : Float(384)\n",
      "      %171 : Float(384, 1, 3, 3)\n",
      "      %172 : Float(384)\n",
      "      %173 : Float(384)\n",
      "      %174 : Float(384)\n",
      "      %175 : Float(384)\n",
      "      %176 : Float(96, 384, 1, 1)\n",
      "      %177 : Float(96)\n",
      "      %178 : Float(96)\n",
      "      %179 : Float(96)\n",
      "      %180 : Float(96)\n",
      "      %181 : Float(96, 64, 1, 1)\n",
      "      %182 : Float(96)\n",
      "      %183 : Float(96)\n",
      "      %184 : Float(96)\n",
      "      %185 : Float(96)\n",
      "      %186 : Float(576, 96, 1, 1)\n",
      "      %187 : Float(576)\n",
      "      %188 : Float(576)\n",
      "      %189 : Float(576)\n",
      "      %190 : Float(576)\n",
      "      %191 : Float(576, 1, 3, 3)\n",
      "      %192 : Float(576)\n",
      "      %193 : Float(576)\n",
      "      %194 : Float(576)\n",
      "      %195 : Float(576)\n",
      "      %196 : Float(96, 576, 1, 1)\n",
      "      %197 : Float(96)\n",
      "      %198 : Float(96)\n",
      "      %199 : Float(96)\n",
      "      %200 : Float(96)\n",
      "      %201 : Float(576, 96, 1, 1)\n",
      "      %202 : Float(576)\n",
      "      %203 : Float(576)\n",
      "      %204 : Float(576)\n",
      "      %205 : Float(576)\n",
      "      %206 : Float(576, 1, 3, 3)\n",
      "      %207 : Float(576)\n",
      "      %208 : Float(576)\n",
      "      %209 : Float(576)\n",
      "      %210 : Float(576)\n",
      "      %211 : Float(96, 576, 1, 1)\n",
      "      %212 : Float(96)\n",
      "      %213 : Float(96)\n",
      "      %214 : Float(96)\n",
      "      %215 : Float(96)\n",
      "      %216 : Float(576, 96, 1, 1)\n",
      "      %217 : Float(576)\n",
      "      %218 : Float(576)\n",
      "      %219 : Float(576)\n",
      "      %220 : Float(576)\n",
      "      %221 : Float(576, 1, 3, 3)\n",
      "      %222 : Float(576)\n",
      "      %223 : Float(576)\n",
      "      %224 : Float(576)\n",
      "      %225 : Float(576)\n",
      "      %226 : Float(160, 576, 1, 1)\n",
      "      %227 : Float(160)\n",
      "      %228 : Float(160)\n",
      "      %229 : Float(160)\n",
      "      %230 : Float(160)\n",
      "      %231 : Float(960, 160, 1, 1)\n",
      "      %232 : Float(960)\n",
      "      %233 : Float(960)\n",
      "      %234 : Float(960)\n",
      "      %235 : Float(960)\n",
      "      %236 : Float(960, 1, 3, 3)\n",
      "      %237 : Float(960)\n",
      "      %238 : Float(960)\n",
      "      %239 : Float(960)\n",
      "      %240 : Float(960)\n",
      "      %241 : Float(160, 960, 1, 1)\n",
      "      %242 : Float(160)\n",
      "      %243 : Float(160)\n",
      "      %244 : Float(160)\n",
      "      %245 : Float(160)\n",
      "      %246 : Float(960, 160, 1, 1)\n",
      "      %247 : Float(960)\n",
      "      %248 : Float(960)\n",
      "      %249 : Float(960)\n",
      "      %250 : Float(960)\n",
      "      %251 : Float(960, 1, 3, 3)\n",
      "      %252 : Float(960)\n",
      "      %253 : Float(960)\n",
      "      %254 : Float(960)\n",
      "      %255 : Float(960)\n",
      "      %256 : Float(160, 960, 1, 1)\n",
      "      %257 : Float(160)\n",
      "      %258 : Float(160)\n",
      "      %259 : Float(160)\n",
      "      %260 : Float(160)\n",
      "      %261 : Float(960, 160, 1, 1)\n",
      "      %262 : Float(960)\n",
      "      %263 : Float(960)\n",
      "      %264 : Float(960)\n",
      "      %265 : Float(960)\n",
      "      %266 : Float(960, 1, 3, 3)\n",
      "      %267 : Float(960)\n",
      "      %268 : Float(960)\n",
      "      %269 : Float(960)\n",
      "      %270 : Float(960)\n",
      "      %271 : Float(320, 960, 1, 1)\n",
      "      %272 : Float(320)\n",
      "      %273 : Float(320)\n",
      "      %274 : Float(320)\n",
      "      %275 : Float(320)\n",
      "      %276 : Float(320, 160, 1, 1)\n",
      "      %277 : Float(320)\n",
      "      %278 : Float(320)\n",
      "      %279 : Float(320)\n",
      "      %280 : Float(320)\n",
      "      %281 : Float(1280, 320, 1, 1)\n",
      "      %282 : Float(1280)\n",
      "      %283 : Float(1280)\n",
      "      %284 : Float(1280)\n",
      "      %285 : Float(1280)\n",
      "      %286 : Float(10, 1280)\n",
      "      %287 : Float(10)) {\n",
      "  %288 : Float(1, 3, 32, 32), %289 : Handle = ^Scatter([0], None, 0)(%0), scope: DataParallel\n",
      "  %290 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%288, %1), scope: DataParallel/MobileNetV2[module]/Conv2d[conv1]\n",
      "  %291 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%290, %2, %3, %4, %5), scope: DataParallel/MobileNetV2[module]/BatchNorm2d[bn1]\n",
      "  %292 : Float(1, 32, 32, 32) = onnx::Relu(%291), scope: DataParallel/MobileNetV2[module]\n",
      "  %293 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%292, %6), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv1]\n",
      "  %294 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%293, %7, %8, %9, %10), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn1]\n",
      "  %295 : Float(1, 32, 32, 32) = onnx::Relu(%294), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n",
      "  %296 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%295, %11), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv2]\n",
      "  %297 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%296, %12, %13, %14, %15), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn2]\n",
      "  %298 : Float(1, 32, 32, 32) = onnx::Relu(%297), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n",
      "  %299 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%298, %16), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv3]\n",
      "  %300 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%299, %17, %18, %19, %20), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn3]\n",
      "  %301 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%292, %21), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Sequential[shortcut]/Conv2d[0]\n",
      "  %302 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%301, %22, %23, %24, %25), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Sequential[shortcut]/BatchNorm2d[1]\n",
      "  %303 : Float(1, 16, 32, 32) = onnx::Add(%300, %302), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n",
      "  %304 : Float(1, 96, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%303, %26), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv1]\n",
      "  %305 : Float(1, 96, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%304, %27, %28, %29, %30), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn1]\n",
      "  %306 : Float(1, 96, 32, 32) = onnx::Relu(%305), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n",
      "  %307 : Float(1, 96, 32, 32) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%306, %31), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv2]\n",
      "  %308 : Float(1, 96, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%307, %32, %33, %34, %35), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn2]\n",
      "  %309 : Float(1, 96, 32, 32) = onnx::Relu(%308), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n",
      "  %310 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%309, %36), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv3]\n",
      "  %311 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%310, %37, %38, %39, %40), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn3]\n",
      "  %312 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%303, %41), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Sequential[shortcut]/Conv2d[0]\n",
      "  %313 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%312, %42, %43, %44, %45), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Sequential[shortcut]/BatchNorm2d[1]\n",
      "  %314 : Float(1, 24, 32, 32) = onnx::Add(%311, %313), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n",
      "  %315 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%314, %46), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv1]\n",
      "  %316 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%315, %47, %48, %49, %50), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn1]\n",
      "  %317 : Float(1, 144, 32, 32) = onnx::Relu(%316), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n",
      "  %318 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%317, %51), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv2]\n",
      "  %319 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%318, %52, %53, %54, %55), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn2]\n",
      "  %320 : Float(1, 144, 32, 32) = onnx::Relu(%319), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n",
      "  %321 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%320, %56), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv3]\n",
      "  %322 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%321, %57, %58, %59, %60), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn3]\n",
      "  %323 : Float(1, 24, 32, 32) = onnx::Add(%322, %314), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n",
      "  %324 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%323, %61), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv1]\n",
      "  %325 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%324, %62, %63, %64, %65), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn1]\n",
      "  %326 : Float(1, 144, 32, 32) = onnx::Relu(%325), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]\n",
      "  %327 : Float(1, 144, 16, 16) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%326, %66), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv2]\n",
      "  %328 : Float(1, 144, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%327, %67, %68, %69, %70), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn2]\n",
      "  %329 : Float(1, 144, 16, 16) = onnx::Relu(%328), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]\n",
      "  %330 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%329, %71), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv3]\n",
      "  %331 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%330, %72, %73, %74, %75), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn3]\n",
      "  %332 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%331, %76), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv1]\n",
      "  %333 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%332, %77, %78, %79, %80), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn1]\n",
      "  %334 : Float(1, 192, 16, 16) = onnx::Relu(%333), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n",
      "  %335 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%334, %81), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv2]\n",
      "  %336 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%335, %82, %83, %84, %85), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn2]\n",
      "  %337 : Float(1, 192, 16, 16) = onnx::Relu(%336), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n",
      "  %338 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%337, %86), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv3]\n",
      "  %339 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%338, %87, %88, %89, %90), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn3]\n",
      "  %340 : Float(1, 32, 16, 16) = onnx::Add(%339, %331), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n",
      "  %341 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%340, %91), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv1]\n",
      "  %342 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%341, %92, %93, %94, %95), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn1]\n",
      "  %343 : Float(1, 192, 16, 16) = onnx::Relu(%342), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n",
      "  %344 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%343, %96), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv2]\n",
      "  %345 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%344, %97, %98, %99, %100), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn2]\n",
      "  %346 : Float(1, 192, 16, 16) = onnx::Relu(%345), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n",
      "  %347 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%346, %101), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv3]\n",
      "  %348 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%347, %102, %103, %104, %105), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn3]\n",
      "  %349 : Float(1, 32, 16, 16) = onnx::Add(%348, %340), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n",
      "  %350 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%349, %106), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv1]\n",
      "  %351 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%350, %107, %108, %109, %110), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn1]\n",
      "  %352 : Float(1, 192, 16, 16) = onnx::Relu(%351), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]\n",
      "  %353 : Float(1, 192, 8, 8) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%352, %111), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv2]\n",
      "  %354 : Float(1, 192, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%353, %112, %113, %114, %115), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn2]\n",
      "  %355 : Float(1, 192, 8, 8) = onnx::Relu(%354), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]\n",
      "  %356 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%355, %116), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv3]\n",
      "  %357 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%356, %117, %118, %119, %120), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn3]\n",
      "  %358 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%357, %121), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv1]\n",
      "  %359 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%358, %122, %123, %124, %125), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn1]\n",
      "  %360 : Float(1, 384, 8, 8) = onnx::Relu(%359), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n",
      "  %361 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%360, %126), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv2]\n",
      "  %362 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%361, %127, %128, %129, %130), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn2]\n",
      "  %363 : Float(1, 384, 8, 8) = onnx::Relu(%362), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n",
      "  %364 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%363, %131), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv3]\n",
      "  %365 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%364, %132, %133, %134, %135), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn3]\n",
      "  %366 : Float(1, 64, 8, 8) = onnx::Add(%365, %357), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n",
      "  %367 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%366, %136), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv1]\n",
      "  %368 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%367, %137, %138, %139, %140), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn1]\n",
      "  %369 : Float(1, 384, 8, 8) = onnx::Relu(%368), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n",
      "  %370 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%369, %141), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv2]\n",
      "  %371 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%370, %142, %143, %144, %145), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn2]\n",
      "  %372 : Float(1, 384, 8, 8) = onnx::Relu(%371), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n",
      "  %373 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%372, %146), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv3]\n",
      "  %374 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%373, %147, %148, %149, %150), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn3]\n",
      "  %375 : Float(1, 64, 8, 8) = onnx::Add(%374, %366), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n",
      "  %376 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%375, %151), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv1]\n",
      "  %377 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%376, %152, %153, %154, %155), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn1]\n",
      "  %378 : Float(1, 384, 8, 8) = onnx::Relu(%377), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n",
      "  %379 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%378, %156), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv2]\n",
      "  %380 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%379, %157, %158, %159, %160), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn2]\n",
      "  %381 : Float(1, 384, 8, 8) = onnx::Relu(%380), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n",
      "  %382 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%381, %161), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv3]\n",
      "  %383 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%382, %162, %163, %164, %165), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn3]\n",
      "  %384 : Float(1, 64, 8, 8) = onnx::Add(%383, %375), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n",
      "  %385 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%384, %166), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv1]\n",
      "  %386 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%385, %167, %168, %169, %170), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn1]\n",
      "  %387 : Float(1, 384, 8, 8) = onnx::Relu(%386), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n",
      "  %388 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%387, %171), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv2]\n",
      "  %389 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%388, %172, %173, %174, %175), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn2]\n",
      "  %390 : Float(1, 384, 8, 8) = onnx::Relu(%389), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n",
      "  %391 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%390, %176), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv3]\n",
      "  %392 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%391, %177, %178, %179, %180), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn3]\n",
      "  %393 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%384, %181), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Sequential[shortcut]/Conv2d[0]\n",
      "  %394 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%393, %182, %183, %184, %185), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Sequential[shortcut]/BatchNorm2d[1]\n",
      "  %395 : Float(1, 96, 8, 8) = onnx::Add(%392, %394), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n",
      "  %396 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%395, %186), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv1]\n",
      "  %397 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%396, %187, %188, %189, %190), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn1]\n",
      "  %398 : Float(1, 576, 8, 8) = onnx::Relu(%397), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n",
      "  %399 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%398, %191), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv2]\n",
      "  %400 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%399, %192, %193, %194, %195), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn2]\n",
      "  %401 : Float(1, 576, 8, 8) = onnx::Relu(%400), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n",
      "  %402 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%401, %196), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv3]\n",
      "  %403 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%402, %197, %198, %199, %200), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn3]\n",
      "  %404 : Float(1, 96, 8, 8) = onnx::Add(%403, %395), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n",
      "  %405 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%404, %201), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv1]\n",
      "  %406 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%405, %202, %203, %204, %205), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn1]\n",
      "  %407 : Float(1, 576, 8, 8) = onnx::Relu(%406), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n",
      "  %408 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%407, %206), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv2]\n",
      "  %409 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%408, %207, %208, %209, %210), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn2]\n",
      "  %410 : Float(1, 576, 8, 8) = onnx::Relu(%409), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n",
      "  %411 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%410, %211), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv3]\n",
      "  %412 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%411, %212, %213, %214, %215), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn3]\n",
      "  %413 : Float(1, 96, 8, 8) = onnx::Add(%412, %404), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n",
      "  %414 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%413, %216), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv1]\n",
      "  %415 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%414, %217, %218, %219, %220), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn1]\n",
      "  %416 : Float(1, 576, 8, 8) = onnx::Relu(%415), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]\n",
      "  %417 : Float(1, 576, 4, 4) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%416, %221), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv2]\n",
      "  %418 : Float(1, 576, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%417, %222, %223, %224, %225), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn2]\n",
      "  %419 : Float(1, 576, 4, 4) = onnx::Relu(%418), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]\n",
      "  %420 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%419, %226), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv3]\n",
      "  %421 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%420, %227, %228, %229, %230), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn3]\n",
      "  %422 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%421, %231), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv1]\n",
      "  %423 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%422, %232, %233, %234, %235), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn1]\n",
      "  %424 : Float(1, 960, 4, 4) = onnx::Relu(%423), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n",
      "  %425 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%424, %236), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv2]\n",
      "  %426 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%425, %237, %238, %239, %240), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn2]\n",
      "  %427 : Float(1, 960, 4, 4) = onnx::Relu(%426), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n",
      "  %428 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%427, %241), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv3]\n",
      "  %429 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%428, %242, %243, %244, %245), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn3]\n",
      "  %430 : Float(1, 160, 4, 4) = onnx::Add(%429, %421), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n",
      "  %431 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%430, %246), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv1]\n",
      "  %432 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%431, %247, %248, %249, %250), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn1]\n",
      "  %433 : Float(1, 960, 4, 4) = onnx::Relu(%432), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n",
      "  %434 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%433, %251), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv2]\n",
      "  %435 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%434, %252, %253, %254, %255), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn2]\n",
      "  %436 : Float(1, 960, 4, 4) = onnx::Relu(%435), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n",
      "  %437 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%436, %256), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv3]\n",
      "  %438 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%437, %257, %258, %259, %260), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn3]\n",
      "  %439 : Float(1, 160, 4, 4) = onnx::Add(%438, %430), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n",
      "  %440 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%439, %261), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv1]\n",
      "  %441 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%440, %262, %263, %264, %265), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn1]\n",
      "  %442 : Float(1, 960, 4, 4) = onnx::Relu(%441), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n",
      "  %443 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%442, %266), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv2]\n",
      "  %444 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%443, %267, %268, %269, %270), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn2]\n",
      "  %445 : Float(1, 960, 4, 4) = onnx::Relu(%444), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n",
      "  %446 : Float(1, 320, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%445, %271), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv3]\n",
      "  %447 : Float(1, 320, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%446, %272, %273, %274, %275), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn3]\n",
      "  %448 : Float(1, 320, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%439, %276), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Sequential[shortcut]/Conv2d[0]\n",
      "  %449 : Float(1, 320, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%448, %277, %278, %279, %280), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Sequential[shortcut]/BatchNorm2d[1]\n",
      "  %450 : Float(1, 320, 4, 4) = onnx::Add(%447, %449), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n",
      "  %451 : Float(1, 1280, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%450, %281), scope: DataParallel/MobileNetV2[module]/Conv2d[conv2]\n",
      "  %452 : Float(1, 1280, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%451, %282, %283, %284, %285), scope: DataParallel/MobileNetV2[module]/BatchNorm2d[bn2]\n",
      "  %453 : Float(1, 1280, 4, 4) = onnx::Relu(%452), scope: DataParallel/MobileNetV2[module]\n",
      "  %454 : Float(1, 1280, 1, 1) = onnx::AveragePool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%453), scope: DataParallel/MobileNetV2[module]\n",
      "  %455 : Float(1, 1280) = onnx::Flatten[axis=1](%454), scope: DataParallel/MobileNetV2[module]\n",
      "  %456 : Float(1, 10) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%455, %286, %287), scope: DataParallel/MobileNetV2[module]/Linear[linear]\n",
      "  return (%456);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX export failed: Couldn't export Python operator Scatter\n\nDefined at:\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py(14): scatter_map\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py(16): scatter_map\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py(29): scatter\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py(36): scatter_kwargs\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py(121): scatter\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py(110): forward\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/modules/module.py(479): _slow_forward\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/modules/module.py(489): __call__\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/jit/__init__.py(288): forward\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/modules/module.py(491): __call__\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/jit/__init__.py(255): get_trace_graph\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/utils.py(134): _export\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/utils.py(84): export\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/__init__.py(25): export\n<ipython-input-3-772a18c7cb6b>(47): <module>\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3267): run_code\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3191): run_ast_nodes\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3020): run_cell_async\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/async_helpers.py(67): _pseudo_sync_runner\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2845): _run_cell\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2819): run_cell\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/zmqshell.py(536): run_cell\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/ipkernel.py(294): do_execute\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(326): wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelbase.py(534): execute_request\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(326): wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelbase.py(267): dispatch_shell\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(326): wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelbase.py(357): process_one\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(1147): run\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(1080): __init__\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(346): wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelbase.py(370): dispatch_queue\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(1147): run\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(1233): inner\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/stack_context.py(300): null_wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/ioloop.py(758): _run_callback\n/opt/conda/lib/python3.6/asyncio/events.py(145): _run\n/opt/conda/lib/python3.6/asyncio/base_events.py(1434): _run_once\n/opt/conda/lib/python3.6/asyncio/base_events.py(422): run_forever\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/platform/asyncio.py(132): start\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelapp.py(505): start\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/traitlets/config/application.py(658): launch_instance\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel_launcher.py(16): <module>\n/opt/conda/lib/python3.6/runpy.py(85): _run_code\n/opt/conda/lib/python3.6/runpy.py(193): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%0 : Float(1, 3, 32, 32)\n      %1 : Float(32, 3, 3, 3)\n      %2 : Float(32)\n      %3 : Float(32)\n      %4 : Float(32)\n      %5 : Float(32)\n      %6 : Float(32, 32, 1, 1)\n      %7 : Float(32)\n      %8 : Float(32)\n      %9 : Float(32)\n      %10 : Float(32)\n      %11 : Float(32, 1, 3, 3)\n      %12 : Float(32)\n      %13 : Float(32)\n      %14 : Float(32)\n      %15 : Float(32)\n      %16 : Float(16, 32, 1, 1)\n      %17 : Float(16)\n      %18 : Float(16)\n      %19 : Float(16)\n      %20 : Float(16)\n      %21 : Float(16, 32, 1, 1)\n      %22 : Float(16)\n      %23 : Float(16)\n      %24 : Float(16)\n      %25 : Float(16)\n      %26 : Float(96, 16, 1, 1)\n      %27 : Float(96)\n      %28 : Float(96)\n      %29 : Float(96)\n      %30 : Float(96)\n      %31 : Float(96, 1, 3, 3)\n      %32 : Float(96)\n      %33 : Float(96)\n      %34 : Float(96)\n      %35 : Float(96)\n      %36 : Float(24, 96, 1, 1)\n      %37 : Float(24)\n      %38 : Float(24)\n      %39 : Float(24)\n      %40 : Float(24)\n      %41 : Float(24, 16, 1, 1)\n      %42 : Float(24)\n      %43 : Float(24)\n      %44 : Float(24)\n      %45 : Float(24)\n      %46 : Float(144, 24, 1, 1)\n      %47 : Float(144)\n      %48 : Float(144)\n      %49 : Float(144)\n      %50 : Float(144)\n      %51 : Float(144, 1, 3, 3)\n      %52 : Float(144)\n      %53 : Float(144)\n      %54 : Float(144)\n      %55 : Float(144)\n      %56 : Float(24, 144, 1, 1)\n      %57 : Float(24)\n      %58 : Float(24)\n      %59 : Float(24)\n      %60 : Float(24)\n      %61 : Float(144, 24, 1, 1)\n      %62 : Float(144)\n      %63 : Float(144)\n      %64 : Float(144)\n      %65 : Float(144)\n      %66 : Float(144, 1, 3, 3)\n      %67 : Float(144)\n      %68 : Float(144)\n      %69 : Float(144)\n      %70 : Float(144)\n      %71 : Float(32, 144, 1, 1)\n      %72 : Float(32)\n      %73 : Float(32)\n      %74 : Float(32)\n      %75 : Float(32)\n      %76 : Float(192, 32, 1, 1)\n      %77 : Float(192)\n      %78 : Float(192)\n      %79 : Float(192)\n      %80 : Float(192)\n      %81 : Float(192, 1, 3, 3)\n      %82 : Float(192)\n      %83 : Float(192)\n      %84 : Float(192)\n      %85 : Float(192)\n      %86 : Float(32, 192, 1, 1)\n      %87 : Float(32)\n      %88 : Float(32)\n      %89 : Float(32)\n      %90 : Float(32)\n      %91 : Float(192, 32, 1, 1)\n      %92 : Float(192)\n      %93 : Float(192)\n      %94 : Float(192)\n      %95 : Float(192)\n      %96 : Float(192, 1, 3, 3)\n      %97 : Float(192)\n      %98 : Float(192)\n      %99 : Float(192)\n      %100 : Float(192)\n      %101 : Float(32, 192, 1, 1)\n      %102 : Float(32)\n      %103 : Float(32)\n      %104 : Float(32)\n      %105 : Float(32)\n      %106 : Float(192, 32, 1, 1)\n      %107 : Float(192)\n      %108 : Float(192)\n      %109 : Float(192)\n      %110 : Float(192)\n      %111 : Float(192, 1, 3, 3)\n      %112 : Float(192)\n      %113 : Float(192)\n      %114 : Float(192)\n      %115 : Float(192)\n      %116 : Float(64, 192, 1, 1)\n      %117 : Float(64)\n      %118 : Float(64)\n      %119 : Float(64)\n      %120 : Float(64)\n      %121 : Float(384, 64, 1, 1)\n      %122 : Float(384)\n      %123 : Float(384)\n      %124 : Float(384)\n      %125 : Float(384)\n      %126 : Float(384, 1, 3, 3)\n      %127 : Float(384)\n      %128 : Float(384)\n      %129 : Float(384)\n      %130 : Float(384)\n      %131 : Float(64, 384, 1, 1)\n      %132 : Float(64)\n      %133 : Float(64)\n      %134 : Float(64)\n      %135 : Float(64)\n      %136 : Float(384, 64, 1, 1)\n      %137 : Float(384)\n      %138 : Float(384)\n      %139 : Float(384)\n      %140 : Float(384)\n      %141 : Float(384, 1, 3, 3)\n      %142 : Float(384)\n      %143 : Float(384)\n      %144 : Float(384)\n      %145 : Float(384)\n      %146 : Float(64, 384, 1, 1)\n      %147 : Float(64)\n      %148 : Float(64)\n      %149 : Float(64)\n      %150 : Float(64)\n      %151 : Float(384, 64, 1, 1)\n      %152 : Float(384)\n      %153 : Float(384)\n      %154 : Float(384)\n      %155 : Float(384)\n      %156 : Float(384, 1, 3, 3)\n      %157 : Float(384)\n      %158 : Float(384)\n      %159 : Float(384)\n      %160 : Float(384)\n      %161 : Float(64, 384, 1, 1)\n      %162 : Float(64)\n      %163 : Float(64)\n      %164 : Float(64)\n      %165 : Float(64)\n      %166 : Float(384, 64, 1, 1)\n      %167 : Float(384)\n      %168 : Float(384)\n      %169 : Float(384)\n      %170 : Float(384)\n      %171 : Float(384, 1, 3, 3)\n      %172 : Float(384)\n      %173 : Float(384)\n      %174 : Float(384)\n      %175 : Float(384)\n      %176 : Float(96, 384, 1, 1)\n      %177 : Float(96)\n      %178 : Float(96)\n      %179 : Float(96)\n      %180 : Float(96)\n      %181 : Float(96, 64, 1, 1)\n      %182 : Float(96)\n      %183 : Float(96)\n      %184 : Float(96)\n      %185 : Float(96)\n      %186 : Float(576, 96, 1, 1)\n      %187 : Float(576)\n      %188 : Float(576)\n      %189 : Float(576)\n      %190 : Float(576)\n      %191 : Float(576, 1, 3, 3)\n      %192 : Float(576)\n      %193 : Float(576)\n      %194 : Float(576)\n      %195 : Float(576)\n      %196 : Float(96, 576, 1, 1)\n      %197 : Float(96)\n      %198 : Float(96)\n      %199 : Float(96)\n      %200 : Float(96)\n      %201 : Float(576, 96, 1, 1)\n      %202 : Float(576)\n      %203 : Float(576)\n      %204 : Float(576)\n      %205 : Float(576)\n      %206 : Float(576, 1, 3, 3)\n      %207 : Float(576)\n      %208 : Float(576)\n      %209 : Float(576)\n      %210 : Float(576)\n      %211 : Float(96, 576, 1, 1)\n      %212 : Float(96)\n      %213 : Float(96)\n      %214 : Float(96)\n      %215 : Float(96)\n      %216 : Float(576, 96, 1, 1)\n      %217 : Float(576)\n      %218 : Float(576)\n      %219 : Float(576)\n      %220 : Float(576)\n      %221 : Float(576, 1, 3, 3)\n      %222 : Float(576)\n      %223 : Float(576)\n      %224 : Float(576)\n      %225 : Float(576)\n      %226 : Float(160, 576, 1, 1)\n      %227 : Float(160)\n      %228 : Float(160)\n      %229 : Float(160)\n      %230 : Float(160)\n      %231 : Float(960, 160, 1, 1)\n      %232 : Float(960)\n      %233 : Float(960)\n      %234 : Float(960)\n      %235 : Float(960)\n      %236 : Float(960, 1, 3, 3)\n      %237 : Float(960)\n      %238 : Float(960)\n      %239 : Float(960)\n      %240 : Float(960)\n      %241 : Float(160, 960, 1, 1)\n      %242 : Float(160)\n      %243 : Float(160)\n      %244 : Float(160)\n      %245 : Float(160)\n      %246 : Float(960, 160, 1, 1)\n      %247 : Float(960)\n      %248 : Float(960)\n      %249 : Float(960)\n      %250 : Float(960)\n      %251 : Float(960, 1, 3, 3)\n      %252 : Float(960)\n      %253 : Float(960)\n      %254 : Float(960)\n      %255 : Float(960)\n      %256 : Float(160, 960, 1, 1)\n      %257 : Float(160)\n      %258 : Float(160)\n      %259 : Float(160)\n      %260 : Float(160)\n      %261 : Float(960, 160, 1, 1)\n      %262 : Float(960)\n      %263 : Float(960)\n      %264 : Float(960)\n      %265 : Float(960)\n      %266 : Float(960, 1, 3, 3)\n      %267 : Float(960)\n      %268 : Float(960)\n      %269 : Float(960)\n      %270 : Float(960)\n      %271 : Float(320, 960, 1, 1)\n      %272 : Float(320)\n      %273 : Float(320)\n      %274 : Float(320)\n      %275 : Float(320)\n      %276 : Float(320, 160, 1, 1)\n      %277 : Float(320)\n      %278 : Float(320)\n      %279 : Float(320)\n      %280 : Float(320)\n      %281 : Float(1280, 320, 1, 1)\n      %282 : Float(1280)\n      %283 : Float(1280)\n      %284 : Float(1280)\n      %285 : Float(1280)\n      %286 : Float(10, 1280)\n      %287 : Float(10)) {\n  %288 : Float(1, 3, 32, 32), %289 : Handle = ^Scatter([0], None, 0)(%0), scope: DataParallel\n  %290 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%288, %1), scope: DataParallel/MobileNetV2[module]/Conv2d[conv1]\n  %291 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%290, %2, %3, %4, %5), scope: DataParallel/MobileNetV2[module]/BatchNorm2d[bn1]\n  %292 : Float(1, 32, 32, 32) = onnx::Relu(%291), scope: DataParallel/MobileNetV2[module]\n  %293 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%292, %6), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv1]\n  %294 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%293, %7, %8, %9, %10), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn1]\n  %295 : Float(1, 32, 32, 32) = onnx::Relu(%294), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n  %296 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%295, %11), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv2]\n  %297 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%296, %12, %13, %14, %15), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn2]\n  %298 : Float(1, 32, 32, 32) = onnx::Relu(%297), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n  %299 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%298, %16), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv3]\n  %300 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%299, %17, %18, %19, %20), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn3]\n  %301 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%292, %21), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Sequential[shortcut]/Conv2d[0]\n  %302 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%301, %22, %23, %24, %25), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Sequential[shortcut]/BatchNorm2d[1]\n  %303 : Float(1, 16, 32, 32) = onnx::Add(%300, %302), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n  %304 : Float(1, 96, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%303, %26), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv1]\n  %305 : Float(1, 96, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%304, %27, %28, %29, %30), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn1]\n  %306 : Float(1, 96, 32, 32) = onnx::Relu(%305), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n  %307 : Float(1, 96, 32, 32) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%306, %31), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv2]\n  %308 : Float(1, 96, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%307, %32, %33, %34, %35), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn2]\n  %309 : Float(1, 96, 32, 32) = onnx::Relu(%308), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n  %310 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%309, %36), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv3]\n  %311 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%310, %37, %38, %39, %40), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn3]\n  %312 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%303, %41), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Sequential[shortcut]/Conv2d[0]\n  %313 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%312, %42, %43, %44, %45), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Sequential[shortcut]/BatchNorm2d[1]\n  %314 : Float(1, 24, 32, 32) = onnx::Add(%311, %313), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n  %315 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%314, %46), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv1]\n  %316 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%315, %47, %48, %49, %50), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn1]\n  %317 : Float(1, 144, 32, 32) = onnx::Relu(%316), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n  %318 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%317, %51), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv2]\n  %319 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%318, %52, %53, %54, %55), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn2]\n  %320 : Float(1, 144, 32, 32) = onnx::Relu(%319), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n  %321 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%320, %56), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv3]\n  %322 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%321, %57, %58, %59, %60), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn3]\n  %323 : Float(1, 24, 32, 32) = onnx::Add(%322, %314), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n  %324 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%323, %61), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv1]\n  %325 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%324, %62, %63, %64, %65), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn1]\n  %326 : Float(1, 144, 32, 32) = onnx::Relu(%325), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]\n  %327 : Float(1, 144, 16, 16) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%326, %66), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv2]\n  %328 : Float(1, 144, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%327, %67, %68, %69, %70), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn2]\n  %329 : Float(1, 144, 16, 16) = onnx::Relu(%328), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]\n  %330 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%329, %71), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv3]\n  %331 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%330, %72, %73, %74, %75), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn3]\n  %332 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%331, %76), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv1]\n  %333 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%332, %77, %78, %79, %80), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn1]\n  %334 : Float(1, 192, 16, 16) = onnx::Relu(%333), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n  %335 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%334, %81), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv2]\n  %336 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%335, %82, %83, %84, %85), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn2]\n  %337 : Float(1, 192, 16, 16) = onnx::Relu(%336), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n  %338 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%337, %86), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv3]\n  %339 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%338, %87, %88, %89, %90), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn3]\n  %340 : Float(1, 32, 16, 16) = onnx::Add(%339, %331), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n  %341 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%340, %91), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv1]\n  %342 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%341, %92, %93, %94, %95), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn1]\n  %343 : Float(1, 192, 16, 16) = onnx::Relu(%342), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n  %344 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%343, %96), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv2]\n  %345 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%344, %97, %98, %99, %100), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn2]\n  %346 : Float(1, 192, 16, 16) = onnx::Relu(%345), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n  %347 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%346, %101), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv3]\n  %348 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%347, %102, %103, %104, %105), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn3]\n  %349 : Float(1, 32, 16, 16) = onnx::Add(%348, %340), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n  %350 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%349, %106), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv1]\n  %351 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%350, %107, %108, %109, %110), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn1]\n  %352 : Float(1, 192, 16, 16) = onnx::Relu(%351), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]\n  %353 : Float(1, 192, 8, 8) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%352, %111), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv2]\n  %354 : Float(1, 192, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%353, %112, %113, %114, %115), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn2]\n  %355 : Float(1, 192, 8, 8) = onnx::Relu(%354), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]\n  %356 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%355, %116), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv3]\n  %357 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%356, %117, %118, %119, %120), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn3]\n  %358 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%357, %121), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv1]\n  %359 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%358, %122, %123, %124, %125), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn1]\n  %360 : Float(1, 384, 8, 8) = onnx::Relu(%359), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n  %361 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%360, %126), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv2]\n  %362 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%361, %127, %128, %129, %130), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn2]\n  %363 : Float(1, 384, 8, 8) = onnx::Relu(%362), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n  %364 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%363, %131), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv3]\n  %365 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%364, %132, %133, %134, %135), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn3]\n  %366 : Float(1, 64, 8, 8) = onnx::Add(%365, %357), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n  %367 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%366, %136), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv1]\n  %368 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%367, %137, %138, %139, %140), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn1]\n  %369 : Float(1, 384, 8, 8) = onnx::Relu(%368), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n  %370 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%369, %141), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv2]\n  %371 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%370, %142, %143, %144, %145), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn2]\n  %372 : Float(1, 384, 8, 8) = onnx::Relu(%371), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n  %373 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%372, %146), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv3]\n  %374 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%373, %147, %148, %149, %150), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn3]\n  %375 : Float(1, 64, 8, 8) = onnx::Add(%374, %366), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n  %376 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%375, %151), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv1]\n  %377 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%376, %152, %153, %154, %155), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn1]\n  %378 : Float(1, 384, 8, 8) = onnx::Relu(%377), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n  %379 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%378, %156), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv2]\n  %380 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%379, %157, %158, %159, %160), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn2]\n  %381 : Float(1, 384, 8, 8) = onnx::Relu(%380), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n  %382 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%381, %161), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv3]\n  %383 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%382, %162, %163, %164, %165), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn3]\n  %384 : Float(1, 64, 8, 8) = onnx::Add(%383, %375), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n  %385 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%384, %166), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv1]\n  %386 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%385, %167, %168, %169, %170), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn1]\n  %387 : Float(1, 384, 8, 8) = onnx::Relu(%386), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n  %388 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%387, %171), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv2]\n  %389 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%388, %172, %173, %174, %175), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn2]\n  %390 : Float(1, 384, 8, 8) = onnx::Relu(%389), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n  %391 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%390, %176), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv3]\n  %392 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%391, %177, %178, %179, %180), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn3]\n  %393 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%384, %181), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Sequential[shortcut]/Conv2d[0]\n  %394 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%393, %182, %183, %184, %185), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Sequential[shortcut]/BatchNorm2d[1]\n  %395 : Float(1, 96, 8, 8) = onnx::Add(%392, %394), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n  %396 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%395, %186), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv1]\n  %397 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%396, %187, %188, %189, %190), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn1]\n  %398 : Float(1, 576, 8, 8) = onnx::Relu(%397), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n  %399 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%398, %191), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv2]\n  %400 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%399, %192, %193, %194, %195), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn2]\n  %401 : Float(1, 576, 8, 8) = onnx::Relu(%400), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n  %402 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%401, %196), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv3]\n  %403 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%402, %197, %198, %199, %200), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn3]\n  %404 : Float(1, 96, 8, 8) = onnx::Add(%403, %395), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n  %405 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%404, %201), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv1]\n  %406 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%405, %202, %203, %204, %205), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn1]\n  %407 : Float(1, 576, 8, 8) = onnx::Relu(%406), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n  %408 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%407, %206), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv2]\n  %409 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%408, %207, %208, %209, %210), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn2]\n  %410 : Float(1, 576, 8, 8) = onnx::Relu(%409), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n  %411 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%410, %211), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv3]\n  %412 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%411, %212, %213, %214, %215), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn3]\n  %413 : Float(1, 96, 8, 8) = onnx::Add(%412, %404), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n  %414 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%413, %216), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv1]\n  %415 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%414, %217, %218, %219, %220), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn1]\n  %416 : Float(1, 576, 8, 8) = onnx::Relu(%415), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]\n  %417 : Float(1, 576, 4, 4) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%416, %221), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv2]\n  %418 : Float(1, 576, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%417, %222, %223, %224, %225), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn2]\n  %419 : Float(1, 576, 4, 4) = onnx::Relu(%418), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]\n  %420 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%419, %226), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv3]\n  %421 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%420, %227, %228, %229, %230), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn3]\n  %422 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%421, %231), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv1]\n  %423 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%422, %232, %233, %234, %235), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn1]\n  %424 : Float(1, 960, 4, 4) = onnx::Relu(%423), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n  %425 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%424, %236), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv2]\n  %426 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%425, %237, %238, %239, %240), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn2]\n  %427 : Float(1, 960, 4, 4) = onnx::Relu(%426), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n  %428 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%427, %241), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv3]\n  %429 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%428, %242, %243, %244, %245), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn3]\n  %430 : Float(1, 160, 4, 4) = onnx::Add(%429, %421), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n  %431 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%430, %246), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv1]\n  %432 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%431, %247, %248, %249, %250), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn1]\n  %433 : Float(1, 960, 4, 4) = onnx::Relu(%432), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n  %434 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%433, %251), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv2]\n  %435 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%434, %252, %253, %254, %255), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn2]\n  %436 : Float(1, 960, 4, 4) = onnx::Relu(%435), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n  %437 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%436, %256), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv3]\n  %438 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%437, %257, %258, %259, %260), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn3]\n  %439 : Float(1, 160, 4, 4) = onnx::Add(%438, %430), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n  %440 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%439, %261), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv1]\n  %441 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%440, %262, %263, %264, %265), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn1]\n  %442 : Float(1, 960, 4, 4) = onnx::Relu(%441), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n  %443 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%442, %266), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv2]\n  %444 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%443, %267, %268, %269, %270), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn2]\n  %445 : Float(1, 960, 4, 4) = onnx::Relu(%444), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n  %446 : Float(1, 320, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%445, %271), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv3]\n  %447 : Float(1, 320, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%446, %272, %273, %274, %275), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn3]\n  %448 : Float(1, 320, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%439, %276), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Sequential[shortcut]/Conv2d[0]\n  %449 : Float(1, 320, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%448, %277, %278, %279, %280), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Sequential[shortcut]/BatchNorm2d[1]\n  %450 : Float(1, 320, 4, 4) = onnx::Add(%447, %449), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n  %451 : Float(1, 1280, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%450, %281), scope: DataParallel/MobileNetV2[module]/Conv2d[conv2]\n  %452 : Float(1, 1280, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%451, %282, %283, %284, %285), scope: DataParallel/MobileNetV2[module]/BatchNorm2d[bn2]\n  %453 : Float(1, 1280, 4, 4) = onnx::Relu(%452), scope: DataParallel/MobileNetV2[module]\n  %454 : Float(1, 1280, 1, 1) = onnx::AveragePool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%453), scope: DataParallel/MobileNetV2[module]\n  %455 : Float(1, 1280) = onnx::Flatten[axis=1](%454), scope: DataParallel/MobileNetV2[module]\n  %456 : Float(1, 10) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%455, %286, %287), scope: DataParallel/MobileNetV2[module]/Linear[linear]\n  return (%456);\n}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-772a18c7cb6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'==> Exporting model..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../mobileNetV2.cifar10.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mas\u001b[0m \u001b[0mATen\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0m_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_type)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# not duck-typed and expects an actual list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         proto, export_map = trace.export(list(_unique_state_dict(model).values()),\n\u001b[0;32m--> 154\u001b[0;31m                                          _onnx_opset_version, defer_weight_export)\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_onnx_opset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ONNX export failed: Couldn't export Python operator Scatter\n\nDefined at:\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py(14): scatter_map\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py(16): scatter_map\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py(29): scatter\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/scatter_gather.py(36): scatter_kwargs\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py(121): scatter\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py(110): forward\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/modules/module.py(479): _slow_forward\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/modules/module.py(489): __call__\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/jit/__init__.py(288): forward\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/nn/modules/module.py(491): __call__\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/jit/__init__.py(255): get_trace_graph\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/utils.py(134): _export\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/utils.py(84): export\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/torch/onnx/__init__.py(25): export\n<ipython-input-3-772a18c7cb6b>(47): <module>\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3267): run_code\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3191): run_ast_nodes\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(3020): run_cell_async\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/async_helpers.py(67): _pseudo_sync_runner\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2845): _run_cell\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py(2819): run_cell\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/zmqshell.py(536): run_cell\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/ipkernel.py(294): do_execute\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(326): wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelbase.py(534): execute_request\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(326): wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelbase.py(267): dispatch_shell\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(326): wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelbase.py(357): process_one\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(1147): run\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(1080): __init__\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(346): wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelbase.py(370): dispatch_queue\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(1147): run\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/gen.py(1233): inner\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/stack_context.py(300): null_wrapper\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/ioloop.py(758): _run_callback\n/opt/conda/lib/python3.6/asyncio/events.py(145): _run\n/opt/conda/lib/python3.6/asyncio/base_events.py(1434): _run_once\n/opt/conda/lib/python3.6/asyncio/base_events.py(422): run_forever\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/tornado/platform/asyncio.py(132): start\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel/kernelapp.py(505): start\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/traitlets/config/application.py(658): launch_instance\n/home/dllab/pytorch-cifar/env/lib/python3.6/site-packages/ipykernel_launcher.py(16): <module>\n/opt/conda/lib/python3.6/runpy.py(85): _run_code\n/opt/conda/lib/python3.6/runpy.py(193): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%0 : Float(1, 3, 32, 32)\n      %1 : Float(32, 3, 3, 3)\n      %2 : Float(32)\n      %3 : Float(32)\n      %4 : Float(32)\n      %5 : Float(32)\n      %6 : Float(32, 32, 1, 1)\n      %7 : Float(32)\n      %8 : Float(32)\n      %9 : Float(32)\n      %10 : Float(32)\n      %11 : Float(32, 1, 3, 3)\n      %12 : Float(32)\n      %13 : Float(32)\n      %14 : Float(32)\n      %15 : Float(32)\n      %16 : Float(16, 32, 1, 1)\n      %17 : Float(16)\n      %18 : Float(16)\n      %19 : Float(16)\n      %20 : Float(16)\n      %21 : Float(16, 32, 1, 1)\n      %22 : Float(16)\n      %23 : Float(16)\n      %24 : Float(16)\n      %25 : Float(16)\n      %26 : Float(96, 16, 1, 1)\n      %27 : Float(96)\n      %28 : Float(96)\n      %29 : Float(96)\n      %30 : Float(96)\n      %31 : Float(96, 1, 3, 3)\n      %32 : Float(96)\n      %33 : Float(96)\n      %34 : Float(96)\n      %35 : Float(96)\n      %36 : Float(24, 96, 1, 1)\n      %37 : Float(24)\n      %38 : Float(24)\n      %39 : Float(24)\n      %40 : Float(24)\n      %41 : Float(24, 16, 1, 1)\n      %42 : Float(24)\n      %43 : Float(24)\n      %44 : Float(24)\n      %45 : Float(24)\n      %46 : Float(144, 24, 1, 1)\n      %47 : Float(144)\n      %48 : Float(144)\n      %49 : Float(144)\n      %50 : Float(144)\n      %51 : Float(144, 1, 3, 3)\n      %52 : Float(144)\n      %53 : Float(144)\n      %54 : Float(144)\n      %55 : Float(144)\n      %56 : Float(24, 144, 1, 1)\n      %57 : Float(24)\n      %58 : Float(24)\n      %59 : Float(24)\n      %60 : Float(24)\n      %61 : Float(144, 24, 1, 1)\n      %62 : Float(144)\n      %63 : Float(144)\n      %64 : Float(144)\n      %65 : Float(144)\n      %66 : Float(144, 1, 3, 3)\n      %67 : Float(144)\n      %68 : Float(144)\n      %69 : Float(144)\n      %70 : Float(144)\n      %71 : Float(32, 144, 1, 1)\n      %72 : Float(32)\n      %73 : Float(32)\n      %74 : Float(32)\n      %75 : Float(32)\n      %76 : Float(192, 32, 1, 1)\n      %77 : Float(192)\n      %78 : Float(192)\n      %79 : Float(192)\n      %80 : Float(192)\n      %81 : Float(192, 1, 3, 3)\n      %82 : Float(192)\n      %83 : Float(192)\n      %84 : Float(192)\n      %85 : Float(192)\n      %86 : Float(32, 192, 1, 1)\n      %87 : Float(32)\n      %88 : Float(32)\n      %89 : Float(32)\n      %90 : Float(32)\n      %91 : Float(192, 32, 1, 1)\n      %92 : Float(192)\n      %93 : Float(192)\n      %94 : Float(192)\n      %95 : Float(192)\n      %96 : Float(192, 1, 3, 3)\n      %97 : Float(192)\n      %98 : Float(192)\n      %99 : Float(192)\n      %100 : Float(192)\n      %101 : Float(32, 192, 1, 1)\n      %102 : Float(32)\n      %103 : Float(32)\n      %104 : Float(32)\n      %105 : Float(32)\n      %106 : Float(192, 32, 1, 1)\n      %107 : Float(192)\n      %108 : Float(192)\n      %109 : Float(192)\n      %110 : Float(192)\n      %111 : Float(192, 1, 3, 3)\n      %112 : Float(192)\n      %113 : Float(192)\n      %114 : Float(192)\n      %115 : Float(192)\n      %116 : Float(64, 192, 1, 1)\n      %117 : Float(64)\n      %118 : Float(64)\n      %119 : Float(64)\n      %120 : Float(64)\n      %121 : Float(384, 64, 1, 1)\n      %122 : Float(384)\n      %123 : Float(384)\n      %124 : Float(384)\n      %125 : Float(384)\n      %126 : Float(384, 1, 3, 3)\n      %127 : Float(384)\n      %128 : Float(384)\n      %129 : Float(384)\n      %130 : Float(384)\n      %131 : Float(64, 384, 1, 1)\n      %132 : Float(64)\n      %133 : Float(64)\n      %134 : Float(64)\n      %135 : Float(64)\n      %136 : Float(384, 64, 1, 1)\n      %137 : Float(384)\n      %138 : Float(384)\n      %139 : Float(384)\n      %140 : Float(384)\n      %141 : Float(384, 1, 3, 3)\n      %142 : Float(384)\n      %143 : Float(384)\n      %144 : Float(384)\n      %145 : Float(384)\n      %146 : Float(64, 384, 1, 1)\n      %147 : Float(64)\n      %148 : Float(64)\n      %149 : Float(64)\n      %150 : Float(64)\n      %151 : Float(384, 64, 1, 1)\n      %152 : Float(384)\n      %153 : Float(384)\n      %154 : Float(384)\n      %155 : Float(384)\n      %156 : Float(384, 1, 3, 3)\n      %157 : Float(384)\n      %158 : Float(384)\n      %159 : Float(384)\n      %160 : Float(384)\n      %161 : Float(64, 384, 1, 1)\n      %162 : Float(64)\n      %163 : Float(64)\n      %164 : Float(64)\n      %165 : Float(64)\n      %166 : Float(384, 64, 1, 1)\n      %167 : Float(384)\n      %168 : Float(384)\n      %169 : Float(384)\n      %170 : Float(384)\n      %171 : Float(384, 1, 3, 3)\n      %172 : Float(384)\n      %173 : Float(384)\n      %174 : Float(384)\n      %175 : Float(384)\n      %176 : Float(96, 384, 1, 1)\n      %177 : Float(96)\n      %178 : Float(96)\n      %179 : Float(96)\n      %180 : Float(96)\n      %181 : Float(96, 64, 1, 1)\n      %182 : Float(96)\n      %183 : Float(96)\n      %184 : Float(96)\n      %185 : Float(96)\n      %186 : Float(576, 96, 1, 1)\n      %187 : Float(576)\n      %188 : Float(576)\n      %189 : Float(576)\n      %190 : Float(576)\n      %191 : Float(576, 1, 3, 3)\n      %192 : Float(576)\n      %193 : Float(576)\n      %194 : Float(576)\n      %195 : Float(576)\n      %196 : Float(96, 576, 1, 1)\n      %197 : Float(96)\n      %198 : Float(96)\n      %199 : Float(96)\n      %200 : Float(96)\n      %201 : Float(576, 96, 1, 1)\n      %202 : Float(576)\n      %203 : Float(576)\n      %204 : Float(576)\n      %205 : Float(576)\n      %206 : Float(576, 1, 3, 3)\n      %207 : Float(576)\n      %208 : Float(576)\n      %209 : Float(576)\n      %210 : Float(576)\n      %211 : Float(96, 576, 1, 1)\n      %212 : Float(96)\n      %213 : Float(96)\n      %214 : Float(96)\n      %215 : Float(96)\n      %216 : Float(576, 96, 1, 1)\n      %217 : Float(576)\n      %218 : Float(576)\n      %219 : Float(576)\n      %220 : Float(576)\n      %221 : Float(576, 1, 3, 3)\n      %222 : Float(576)\n      %223 : Float(576)\n      %224 : Float(576)\n      %225 : Float(576)\n      %226 : Float(160, 576, 1, 1)\n      %227 : Float(160)\n      %228 : Float(160)\n      %229 : Float(160)\n      %230 : Float(160)\n      %231 : Float(960, 160, 1, 1)\n      %232 : Float(960)\n      %233 : Float(960)\n      %234 : Float(960)\n      %235 : Float(960)\n      %236 : Float(960, 1, 3, 3)\n      %237 : Float(960)\n      %238 : Float(960)\n      %239 : Float(960)\n      %240 : Float(960)\n      %241 : Float(160, 960, 1, 1)\n      %242 : Float(160)\n      %243 : Float(160)\n      %244 : Float(160)\n      %245 : Float(160)\n      %246 : Float(960, 160, 1, 1)\n      %247 : Float(960)\n      %248 : Float(960)\n      %249 : Float(960)\n      %250 : Float(960)\n      %251 : Float(960, 1, 3, 3)\n      %252 : Float(960)\n      %253 : Float(960)\n      %254 : Float(960)\n      %255 : Float(960)\n      %256 : Float(160, 960, 1, 1)\n      %257 : Float(160)\n      %258 : Float(160)\n      %259 : Float(160)\n      %260 : Float(160)\n      %261 : Float(960, 160, 1, 1)\n      %262 : Float(960)\n      %263 : Float(960)\n      %264 : Float(960)\n      %265 : Float(960)\n      %266 : Float(960, 1, 3, 3)\n      %267 : Float(960)\n      %268 : Float(960)\n      %269 : Float(960)\n      %270 : Float(960)\n      %271 : Float(320, 960, 1, 1)\n      %272 : Float(320)\n      %273 : Float(320)\n      %274 : Float(320)\n      %275 : Float(320)\n      %276 : Float(320, 160, 1, 1)\n      %277 : Float(320)\n      %278 : Float(320)\n      %279 : Float(320)\n      %280 : Float(320)\n      %281 : Float(1280, 320, 1, 1)\n      %282 : Float(1280)\n      %283 : Float(1280)\n      %284 : Float(1280)\n      %285 : Float(1280)\n      %286 : Float(10, 1280)\n      %287 : Float(10)) {\n  %288 : Float(1, 3, 32, 32), %289 : Handle = ^Scatter([0], None, 0)(%0), scope: DataParallel\n  %290 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%288, %1), scope: DataParallel/MobileNetV2[module]/Conv2d[conv1]\n  %291 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%290, %2, %3, %4, %5), scope: DataParallel/MobileNetV2[module]/BatchNorm2d[bn1]\n  %292 : Float(1, 32, 32, 32) = onnx::Relu(%291), scope: DataParallel/MobileNetV2[module]\n  %293 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%292, %6), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv1]\n  %294 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%293, %7, %8, %9, %10), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn1]\n  %295 : Float(1, 32, 32, 32) = onnx::Relu(%294), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n  %296 : Float(1, 32, 32, 32) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%295, %11), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv2]\n  %297 : Float(1, 32, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%296, %12, %13, %14, %15), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn2]\n  %298 : Float(1, 32, 32, 32) = onnx::Relu(%297), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n  %299 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%298, %16), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Conv2d[conv3]\n  %300 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%299, %17, %18, %19, %20), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/BatchNorm2d[bn3]\n  %301 : Float(1, 16, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%292, %21), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Sequential[shortcut]/Conv2d[0]\n  %302 : Float(1, 16, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%301, %22, %23, %24, %25), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]/Sequential[shortcut]/BatchNorm2d[1]\n  %303 : Float(1, 16, 32, 32) = onnx::Add(%300, %302), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[0]\n  %304 : Float(1, 96, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%303, %26), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv1]\n  %305 : Float(1, 96, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%304, %27, %28, %29, %30), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn1]\n  %306 : Float(1, 96, 32, 32) = onnx::Relu(%305), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n  %307 : Float(1, 96, 32, 32) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%306, %31), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv2]\n  %308 : Float(1, 96, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%307, %32, %33, %34, %35), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn2]\n  %309 : Float(1, 96, 32, 32) = onnx::Relu(%308), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n  %310 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%309, %36), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Conv2d[conv3]\n  %311 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%310, %37, %38, %39, %40), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/BatchNorm2d[bn3]\n  %312 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%303, %41), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Sequential[shortcut]/Conv2d[0]\n  %313 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%312, %42, %43, %44, %45), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]/Sequential[shortcut]/BatchNorm2d[1]\n  %314 : Float(1, 24, 32, 32) = onnx::Add(%311, %313), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[1]\n  %315 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%314, %46), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv1]\n  %316 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%315, %47, %48, %49, %50), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn1]\n  %317 : Float(1, 144, 32, 32) = onnx::Relu(%316), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n  %318 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%317, %51), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv2]\n  %319 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%318, %52, %53, %54, %55), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn2]\n  %320 : Float(1, 144, 32, 32) = onnx::Relu(%319), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n  %321 : Float(1, 24, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%320, %56), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/Conv2d[conv3]\n  %322 : Float(1, 24, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%321, %57, %58, %59, %60), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]/BatchNorm2d[bn3]\n  %323 : Float(1, 24, 32, 32) = onnx::Add(%322, %314), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[2]\n  %324 : Float(1, 144, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%323, %61), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv1]\n  %325 : Float(1, 144, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%324, %62, %63, %64, %65), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn1]\n  %326 : Float(1, 144, 32, 32) = onnx::Relu(%325), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]\n  %327 : Float(1, 144, 16, 16) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%326, %66), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv2]\n  %328 : Float(1, 144, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%327, %67, %68, %69, %70), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn2]\n  %329 : Float(1, 144, 16, 16) = onnx::Relu(%328), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]\n  %330 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%329, %71), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/Conv2d[conv3]\n  %331 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%330, %72, %73, %74, %75), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[3]/BatchNorm2d[bn3]\n  %332 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%331, %76), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv1]\n  %333 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%332, %77, %78, %79, %80), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn1]\n  %334 : Float(1, 192, 16, 16) = onnx::Relu(%333), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n  %335 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%334, %81), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv2]\n  %336 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%335, %82, %83, %84, %85), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn2]\n  %337 : Float(1, 192, 16, 16) = onnx::Relu(%336), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n  %338 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%337, %86), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/Conv2d[conv3]\n  %339 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%338, %87, %88, %89, %90), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]/BatchNorm2d[bn3]\n  %340 : Float(1, 32, 16, 16) = onnx::Add(%339, %331), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[4]\n  %341 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%340, %91), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv1]\n  %342 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%341, %92, %93, %94, %95), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn1]\n  %343 : Float(1, 192, 16, 16) = onnx::Relu(%342), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n  %344 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%343, %96), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv2]\n  %345 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%344, %97, %98, %99, %100), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn2]\n  %346 : Float(1, 192, 16, 16) = onnx::Relu(%345), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n  %347 : Float(1, 32, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%346, %101), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/Conv2d[conv3]\n  %348 : Float(1, 32, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%347, %102, %103, %104, %105), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]/BatchNorm2d[bn3]\n  %349 : Float(1, 32, 16, 16) = onnx::Add(%348, %340), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[5]\n  %350 : Float(1, 192, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%349, %106), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv1]\n  %351 : Float(1, 192, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%350, %107, %108, %109, %110), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn1]\n  %352 : Float(1, 192, 16, 16) = onnx::Relu(%351), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]\n  %353 : Float(1, 192, 8, 8) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%352, %111), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv2]\n  %354 : Float(1, 192, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%353, %112, %113, %114, %115), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn2]\n  %355 : Float(1, 192, 8, 8) = onnx::Relu(%354), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]\n  %356 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%355, %116), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/Conv2d[conv3]\n  %357 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%356, %117, %118, %119, %120), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[6]/BatchNorm2d[bn3]\n  %358 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%357, %121), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv1]\n  %359 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%358, %122, %123, %124, %125), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn1]\n  %360 : Float(1, 384, 8, 8) = onnx::Relu(%359), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n  %361 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%360, %126), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv2]\n  %362 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%361, %127, %128, %129, %130), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn2]\n  %363 : Float(1, 384, 8, 8) = onnx::Relu(%362), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n  %364 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%363, %131), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/Conv2d[conv3]\n  %365 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%364, %132, %133, %134, %135), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]/BatchNorm2d[bn3]\n  %366 : Float(1, 64, 8, 8) = onnx::Add(%365, %357), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[7]\n  %367 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%366, %136), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv1]\n  %368 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%367, %137, %138, %139, %140), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn1]\n  %369 : Float(1, 384, 8, 8) = onnx::Relu(%368), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n  %370 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%369, %141), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv2]\n  %371 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%370, %142, %143, %144, %145), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn2]\n  %372 : Float(1, 384, 8, 8) = onnx::Relu(%371), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n  %373 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%372, %146), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/Conv2d[conv3]\n  %374 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%373, %147, %148, %149, %150), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]/BatchNorm2d[bn3]\n  %375 : Float(1, 64, 8, 8) = onnx::Add(%374, %366), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[8]\n  %376 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%375, %151), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv1]\n  %377 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%376, %152, %153, %154, %155), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn1]\n  %378 : Float(1, 384, 8, 8) = onnx::Relu(%377), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n  %379 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%378, %156), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv2]\n  %380 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%379, %157, %158, %159, %160), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn2]\n  %381 : Float(1, 384, 8, 8) = onnx::Relu(%380), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n  %382 : Float(1, 64, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%381, %161), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/Conv2d[conv3]\n  %383 : Float(1, 64, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%382, %162, %163, %164, %165), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]/BatchNorm2d[bn3]\n  %384 : Float(1, 64, 8, 8) = onnx::Add(%383, %375), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[9]\n  %385 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%384, %166), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv1]\n  %386 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%385, %167, %168, %169, %170), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn1]\n  %387 : Float(1, 384, 8, 8) = onnx::Relu(%386), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n  %388 : Float(1, 384, 8, 8) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%387, %171), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv2]\n  %389 : Float(1, 384, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%388, %172, %173, %174, %175), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn2]\n  %390 : Float(1, 384, 8, 8) = onnx::Relu(%389), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n  %391 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%390, %176), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Conv2d[conv3]\n  %392 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%391, %177, %178, %179, %180), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/BatchNorm2d[bn3]\n  %393 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%384, %181), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Sequential[shortcut]/Conv2d[0]\n  %394 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%393, %182, %183, %184, %185), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]/Sequential[shortcut]/BatchNorm2d[1]\n  %395 : Float(1, 96, 8, 8) = onnx::Add(%392, %394), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[10]\n  %396 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%395, %186), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv1]\n  %397 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%396, %187, %188, %189, %190), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn1]\n  %398 : Float(1, 576, 8, 8) = onnx::Relu(%397), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n  %399 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%398, %191), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv2]\n  %400 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%399, %192, %193, %194, %195), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn2]\n  %401 : Float(1, 576, 8, 8) = onnx::Relu(%400), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n  %402 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%401, %196), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/Conv2d[conv3]\n  %403 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%402, %197, %198, %199, %200), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]/BatchNorm2d[bn3]\n  %404 : Float(1, 96, 8, 8) = onnx::Add(%403, %395), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[11]\n  %405 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%404, %201), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv1]\n  %406 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%405, %202, %203, %204, %205), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn1]\n  %407 : Float(1, 576, 8, 8) = onnx::Relu(%406), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n  %408 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%407, %206), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv2]\n  %409 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%408, %207, %208, %209, %210), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn2]\n  %410 : Float(1, 576, 8, 8) = onnx::Relu(%409), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n  %411 : Float(1, 96, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%410, %211), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/Conv2d[conv3]\n  %412 : Float(1, 96, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%411, %212, %213, %214, %215), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]/BatchNorm2d[bn3]\n  %413 : Float(1, 96, 8, 8) = onnx::Add(%412, %404), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[12]\n  %414 : Float(1, 576, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%413, %216), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv1]\n  %415 : Float(1, 576, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%414, %217, %218, %219, %220), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn1]\n  %416 : Float(1, 576, 8, 8) = onnx::Relu(%415), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]\n  %417 : Float(1, 576, 4, 4) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%416, %221), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv2]\n  %418 : Float(1, 576, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%417, %222, %223, %224, %225), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn2]\n  %419 : Float(1, 576, 4, 4) = onnx::Relu(%418), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]\n  %420 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%419, %226), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/Conv2d[conv3]\n  %421 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%420, %227, %228, %229, %230), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[13]/BatchNorm2d[bn3]\n  %422 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%421, %231), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv1]\n  %423 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%422, %232, %233, %234, %235), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn1]\n  %424 : Float(1, 960, 4, 4) = onnx::Relu(%423), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n  %425 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%424, %236), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv2]\n  %426 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%425, %237, %238, %239, %240), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn2]\n  %427 : Float(1, 960, 4, 4) = onnx::Relu(%426), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n  %428 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%427, %241), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/Conv2d[conv3]\n  %429 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%428, %242, %243, %244, %245), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]/BatchNorm2d[bn3]\n  %430 : Float(1, 160, 4, 4) = onnx::Add(%429, %421), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[14]\n  %431 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%430, %246), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv1]\n  %432 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%431, %247, %248, %249, %250), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn1]\n  %433 : Float(1, 960, 4, 4) = onnx::Relu(%432), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n  %434 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%433, %251), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv2]\n  %435 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%434, %252, %253, %254, %255), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn2]\n  %436 : Float(1, 960, 4, 4) = onnx::Relu(%435), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n  %437 : Float(1, 160, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%436, %256), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/Conv2d[conv3]\n  %438 : Float(1, 160, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%437, %257, %258, %259, %260), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]/BatchNorm2d[bn3]\n  %439 : Float(1, 160, 4, 4) = onnx::Add(%438, %430), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[15]\n  %440 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%439, %261), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv1]\n  %441 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%440, %262, %263, %264, %265), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn1]\n  %442 : Float(1, 960, 4, 4) = onnx::Relu(%441), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n  %443 : Float(1, 960, 4, 4) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%442, %266), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv2]\n  %444 : Float(1, 960, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%443, %267, %268, %269, %270), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn2]\n  %445 : Float(1, 960, 4, 4) = onnx::Relu(%444), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n  %446 : Float(1, 320, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%445, %271), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Conv2d[conv3]\n  %447 : Float(1, 320, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%446, %272, %273, %274, %275), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/BatchNorm2d[bn3]\n  %448 : Float(1, 320, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%439, %276), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Sequential[shortcut]/Conv2d[0]\n  %449 : Float(1, 320, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%448, %277, %278, %279, %280), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]/Sequential[shortcut]/BatchNorm2d[1]\n  %450 : Float(1, 320, 4, 4) = onnx::Add(%447, %449), scope: DataParallel/MobileNetV2[module]/Sequential[layers]/Block[16]\n  %451 : Float(1, 1280, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%450, %281), scope: DataParallel/MobileNetV2[module]/Conv2d[conv2]\n  %452 : Float(1, 1280, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=0.9](%451, %282, %283, %284, %285), scope: DataParallel/MobileNetV2[module]/BatchNorm2d[bn2]\n  %453 : Float(1, 1280, 4, 4) = onnx::Relu(%452), scope: DataParallel/MobileNetV2[module]\n  %454 : Float(1, 1280, 1, 1) = onnx::AveragePool[kernel_shape=[4, 4], pads=[0, 0, 0, 0], strides=[4, 4]](%453), scope: DataParallel/MobileNetV2[module]\n  %455 : Float(1, 1280) = onnx::Flatten[axis=1](%454), scope: DataParallel/MobileNetV2[module]\n  %456 : Float(1, 10) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%455, %286, %287), scope: DataParallel/MobileNetV2[module]/Linear[linear]\n  return (%456);\n}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# net = VGG('VGG19')\n",
    "# net = ResNet18()\n",
    "# net = PreActResNet18()\n",
    "# net = GoogLeNet()\n",
    "# net = DenseNet121()\n",
    "# net = ResNeXt29_2x64d()\n",
    "# net = MobileNet()\n",
    "net = MobileNetV2()\n",
    "# net = DPN92()\n",
    "# net = ShuffleNetG2()\n",
    "# net = SENet18()\n",
    "# net = ShuffleNetV2(1)\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load checkpoint.\n",
    "print('==> Resuming from checkpoint..')\n",
    "checkpoint = torch.load('/tmp/work/checkpoint/ckpt.cifar10.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "# Export model\n",
    "print('==> Exporting model..')\n",
    "dummy_input = Variable(torch.randn(1, 3, 32, 32), requires_grad=False)\n",
    "torch.onnx.export(net, dummy_input, \"../mobileNetV2.cifar10.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    'net': net.module.state_dict(),\n",
    "    'acc': checkpoint['acc'],\n",
    "    'epoch': checkpoint['epoch'],\n",
    "}\n",
    "\n",
    "torch.save(state, '../mobileNetV2.cifar10.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorRT deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "\n",
    "def build_engine(onnx_model='./resnet18_food11.onnx', max_batch_size=256):\n",
    "    TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "    with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        # Configure the builder here.\n",
    "        builder.max_batch_size = max_batch_size\n",
    "        builder.max_workspace_size = 1 <<  20\n",
    "        # Parse the model to create a network.\n",
    "        with open(onnx_model, 'rb') as model:\n",
    "            parser.parse(model.read())\n",
    "        # Build and return the engine. Note that the builder, network and parser are destroyed when this function returns.\n",
    "        return builder.build_cuda_engine(network)\n",
    "    \n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    \n",
    "# Allocates all buffers required for an engine, i.e. host/device inputs/outputs.\n",
    "def allocate_buffers(engine):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    bindings = []\n",
    "    stream = cuda.Stream()\n",
    "    for binding in engine:\n",
    "        size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "        # Allocate host and device buffers\n",
    "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "        # Append the device buffer to device bindings.\n",
    "        bindings.append(int(device_mem))\n",
    "        # Append to the appropriate list.\n",
    "        if engine.binding_is_input(binding):\n",
    "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "        else:\n",
    "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    return inputs, outputs, bindings, stream\n",
    "\n",
    "def do_inference(context, bindings, inputs, outputs, stream, batch_size=1):\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.init()\n",
    "\n",
    "max_batch_size = 1024\n",
    "onnx_model = '../mobileNetV2.cifar10.onnx'\n",
    "engine = build_engine(onnx_model, max_batch_size=max_batch_size)\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# input_image_paths = glob.glob('./data/*.npy')\n",
    "# images = []\n",
    "# labels = []\n",
    "# for im_path in input_image_paths:\n",
    "#     image = np.load(im_path)\n",
    "#     images.append(image)\n",
    "#     labels.append(os.path.basename(im_path).split(sep='_')[0])\n",
    "# images = np.asarray(images)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.47889522, 0.47227842, 0.43047404],  std=[0.24205776, 0.23828046, 0.25874835]),\n",
    "])\n",
    "testset = torchvision.datasets.ImageFolder(root='/tmp/work/data/CINIC-10/test/', transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "print('batch size: ' + str(batch_size))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "inputs, outputs, bindings, stream = allocate_buffers(engine)\n",
    "#for idx in range(0, len(images), batch_size):\n",
    "for idx, (images, labels) in enumerate(testloader):\n",
    "    images = np.asarray(images)\n",
    "    inputs[0].host = images[idx: idx+batch_size]\n",
    "    pred = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, \n",
    "                        stream=stream, batch_size=batch_size)\n",
    "    pred = np.asarray(pred).reshape(-1,10)\n",
    "    pred = np.argmax(pred)\n",
    "    correct += np.sum(pred == labels)\n",
    "    total += len(labels)\n",
    "#     for i in range(len(images)):\n",
    "#         predicted_label = str(np.argmax(pred[i]))\n",
    "#         if(predicted_label == labels[idx+i]):\n",
    "#             correct += 1\n",
    "accuracy = correct / total\n",
    "print('acc: ' + str(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlsr",
   "language": "python",
   "name": "dlsr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
